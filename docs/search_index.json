[
["index.html", "Delivering Data Science Products via Packages 1 Welcome Who should read this What you need for this book Conventions used in this book Feedback Acknowledgments", " Delivering Data Science Products via Packages 2020-06-08 1 Welcome Packages are the fundamental units of reproducible R and Python code. They include reusable components, the documentation that describes how to use them, requirements to ensure the user can apply them and tests to ensure consistent and reliable functionality. In this book you’ll learn how to turn your code into packages so that you, your teammates, and others can easily download and use. Writing a package can seem overwhelming at first. So start with the basics and improve it over time. It doesn’t matter if your first version isn’t perfect as long as the next version is better. Who should read this TBD This module makes a few assumptions of your established knowledge regarding your programming skills. Below are some important assumptions made and resources to read through if you feel inadequately prepared: Complete after rest of material is finalized. Assumptions Resource Resource You should be familiar with… You should be familiar with… You should be familiar with… You should be familiar with… What you need for this book TBD Conventions used in this book The following typographical conventions are used in this book: strong italic: indicates new terms, bold: indicates package &amp; file names, inline code: monospaced highlighted text indicates functions or other commands that could be typed literally by the user, code chunk: indicates commands or other text that could be typed literally by the user 1 + 2 ## [1] 3 We will also refer to both R and Python throughout. When discussing one or the other we will typically label with the appropriate icons: Python: R: In addition to the general text used throughout, you will notice the following code chunks: Signifies a tip or suggestion Signifies a general note Signifies a warning or caution Feedback Reader comments are greatly appreciated. To report errors or bugs please post an issue at https://github.com/misk-data-science/misk-packages/issues. Acknowledgments TBD "],
["intro.html", "2 Introduction to Packaging 2.1 Why is packaging important 2.2 When packaging might not be needed 2.3 An opinionated approach", " 2 Introduction to Packaging Often, small snippets of code grow in usefulness and importance, which creates a need to share and distribute their contents. and libraries require packaging, otherwise distributing code becomes problematic and brittle. A package bundles together code, data, documentation, and tests, and is easy to share with others. People often use the terms “package” and “library” synonymously. Although there are some semantical differences between R and Python, here is how you can think of the two terms: package: generally refers to source code that is bundled up in a way that a package manager can host. PyPI and CRAN are the two primary public package managers for Python and R. When you pip install pkg (r fontawesome::fa(“python”)) or install.packages(“pkg”) (r fontawesome::fa(“r-project”)) you are installing the pkg package from a package manager onto a computer. library: generally refers to a centralized location on an operating system where installed package source code resides and can be imported into a current session (i.e. /usr/lib/R/library). When you use pip list (r fontawesome::fa(“python”)) or installed.packages() (r fontawesome::fa(“r-project”)) you will see a list of installed packages, which we refer to as libraries. When you run sys.path (Python) or .libPaths() (R) you will get the path to the library where your installed packages are stored. 2.1 Why is packaging important Why write a package? To share with others: Bundling your code into a package makes it easy for other people to use it, because like you, they already know how to use packages. If your code is in a package, any or user can easily download it, install it and learn how to use it. To make processes reproducible: When certain code processes are repeated, rather than copy-n-pasting (error prone!) packaging helps to ensure the same procedures are executed in the same way. This leads to standardized tools for standardized conventions and can save you and others time. To track changes: Packaging helps to formulize version changes of a project. Versioning allows developers a way to communicate the type of changes made to a project (i.e. bug fixes versus feature enhancement). It also allows users to “pin” a specific version that works for their project. For example, although a current package may have a version 3.2.1, your project depends on specific functionality provided in version 2.9.7. Pinning allows you to request and use that specific version. To communicate with users: Beyond versioning, packaging helps with communication between developers and end-users. Detailed documentation helps the end-users implement the code, a change log can communcate the progression of a package over its versions, users can communicate to the developers regarding bugs they’ve found or suggested feature enhancements. To provide reliability: Packaging helps to modularize code in a way that allows for, and simplifies, testing procedures. This means as your source code grows, or as you get feedback from end-users, so should your test suite grow to help improve reliability of the code base. This results in code that is reliable and trustworthy. To deploy production work: You may have code that is never reused by others; however, the code is put into production to formalize the processesing and output of the code. Packaging your project is a great way to organize, maintain, and distribute your work into production. 2.2 When packaging might not be needed To be clear, it is not necessary to package your code to address all the bullets in the previous section; but it will definitely make them easier to achieve. However, there are times when writing a package is not necessary. For example: Exploratory analysis: The exploratory phase of a project is very interactive and contains many unknowns. You may find yourself repeating some code, which may be a good time to write and reuse small functions. However, this is not the phase to start writing a package. It’s best to wait and see what results from your exploratory analysis. If there are steps in the process (i.e. data prep, model execution) that you later determine are common steps that will often be repeated in the future then a package may result from post-exploration project review. One-off projects: Many times we perform one-off ad-hoc projects. Sometimes we may be able to abstract some steps in these projects that may be repeated but often these projects contain very unique steps that are not often repeated. You most likely will use packages in your analysis but writing a package based on a one-off project is rarely a good use of time. Small scripts: Sometimes a simple , , or Bash script can go a long way and serve your primary purpose. Small individual scripts can be easy to build, execute and orchestrate; however, if you notice this small script starting to grow in size and use then it’s time to start thinking of converting it to a package. Although the above type of work may not justify a package, it often still justifies good software engineering practices such as modularity and unit tests! 2.3 An opinionated approach It is important to understand that there are several approaches and strategies to writing packages. Even within a single language there are different ways to structure a package. Consequently, understand that this book demonstrates the best practices we have found for developing, maintaining, and distributing packages. Our goal is to provide you with a short runway to writing packages as quickly as possible while following commonly used best practices. This is a lot to learn, but don’t feel overwhelmed. Start with a minimal subset of useful features and build up over time. As you write more packages you will begin to learn the lower-level details and alternative options. Do not shy away from these details as we highly recommend that you learn them. In fact, below are some additional resources that will take you to the official R and Python packaging documentation. Realize that the details in these documents can make them challenging to read. That is ok and to be expected. Our suggestion is to get the basics down, which we cover in this book, and slowly expand your knowledge base by writing more packages. : Creating R Extensions : Python Packaging User Guide "],
["structure.html", "3 Package Structure 3.1 example 3.2 example", " 3 Package Structure Packages have a specific structure required to be bundable, deployable, and usable. There are a set of minimum files required for both and packages but you will often see additional files in packages. Though how these files are actually named will differ between and , the organization follows a very similar pattern. The primary files and directories you will be concerned about include: Package metadata: Every package requires important metadata about the package. This file will declare various information such as package name, description, dependencies, author(s), contact information and more. Chapter 5 will discuss the details of this file. Source code directory: This is the directory that contains all the source code for end-user functionality. Here you will organize your classes, functions, etc. into one or more .R / .py scripts. Chapter 6 will discuss requirements, approaches and best practices for organizing this directory. Test directory: Every package should always contain a testing framework. These tests should include a minimum of unit tests but can also contain integration or environment specific tests. Chapter 7 will discuss the most common test approaches for and . Documentation directory: Although not necessary, good packages often will have detailed documentation hosted as a static website. These files are generally kept in a /docs folder. Chapter 11 will discuss how to make beautiful websites for your package. License file: Specifies who can and cannot use your package. This file is related to specifications made in the metadata file and will be discussed in Chapter 5. Changelog: A changelog is a log or record of all notable changes made to a project. We will discuss the changelog in Chapter 9. README: The README is often one of the first files a user sees when going to the source code location (typically Github). A good README will provide useful instructions to get started using the package quickly and also where to go to find more detailed information. We will discuss what a good README looks like in Chapter 10. Other various config or requirement files: You will often see additional files in packages. These may be various configuration files or other package components. Many of these you will be introduced along the way through this book and others will be explicitly discussed in Chapter 5.7. This general structure will look like the following and the sections that follow will illustrate and describe the exact structure setup for each language. . ├── package metadata file ├── source code directory │ ├── script 1 │ ├── script 2 │ └── script n ├── test directory │ ├── script 1 │ ├── script 2 │ └── script n ├── documentation directory │ └── various doc files ├── license file ├── changelog file ├── README └── other various config files and components For the sections that follow let’s assume we are creating a package called mypkg. 3.1 example Within R, the basic structure of your package will look like the following. The unique items here are: DESCRIPTION: This is the file that contains the primary package metadata. R/: The R directory is where all the source code resides. NEWS: It is common convention in many R packages to title the changelog as “NEWS”. mypkg ├── DESCRIPTION ├── R/ ├── tests/ ├── docs/ ├── LICENSE ├── NEWS └── README The rest of the files are consistent with the previous section. As you’ll see in the next chapter, additional files will be produced when we build the package but these are the primary directories and files to get going with an R package. 3.2 example Within Python, the basic structure of your package will look like the following. The unique items here are: setup.py: This is the file that contains the primary package metadata. src/: The src directory is where all the source code resides. mypkg ├── setup.py ├── src/ ├── tests/ ├── docs/ ├── LICENSE ├── CHANGELOG └── README The rest of the files are consistent with the first section. As you’ll see in the next chapter, additional files often included to help configure the developer environment for a package but these are the primary directories and files to create a baseline Python package. "],
["workflow.html", "4 Development Workflow 4.1 Create the package 4.2 Setup a virtual environment 4.3 Add new functionality 4.4 Document 4.5 Version control 4.6 example 4.7 example", " 4 Development Workflow As data scientists, we get used to common workflows that exist in exploring and modeling data. However, the package development workflow is often unique from how we are used to working. This chapter is designed to get you started on a small package so you can experience the typical workflow. First, we’ll discuss the common steps and then we will work through them for both an and version of the package. 4.1 Create the package Once you have determined the need to create a package, the first thing we need to do is identify a package name, create the basic package structure, and connect it to a version control system (i.e. Github) of interest. 4.1.1 Naming Naming our package is important. There are certain requirements we need to adhere to but, also, the name you choose should be easy to remember and follow the respective languages idiomatic approach to naming. Moreover, the name you choose should not already exist. and have slightly different requirements regarding acceptable names. In both languages, you can only use letters and numbers; however, you can’t start the name with a number. In your name can contain a . but not a - or _ while in your name can contain all three. In both languages you can combine upper and lowercase letters in the name. However, our advice is to keep the name short, all lowercase, and with no separator when possible. Examples of good approaches to name include: numpy dplyr pandas keras Once you’ve come up with a name or two you probably want to make sure that the name is not already being used. The package managers (CRAN &amp; PyPI) do not allow duplicate names so your name must be unique. Even if you don’t intend to share your package publicly, you should avoid duplicate names if possible. Both and have tools that make this easy to do and we’ll cover them in the hands-on sections of this chapter. 4.1.2 Create Once you have a name its time to create the package. This includes determining where the package will live on your operating system and creating the bare bones framework of the package. When creating a package, the source code location (path) refers to where the source lives, not where the installed form lives. Recall in Chapter 2 that installed packages all live within a library directory. But when developing, you will keep the source code somewhere else. Where should you keep source packages? The main principle is that this location should be distinct from where installed packages live. In the absence of external considerations, a typical user should designate a directory inside their home directory for and (source) packages. This may be in directories such as ~/Desktop/Packages/ or /r/packages and /python/packages. Some of us use one directory for this, others divide source packages among a few directories. This probably reflects that we are primarily tool-builders. An academic researcher might organize their files around individual publications, whereas a data scientist might organize around data products and reports. There is no particular technical or traditional reason for one specific approach. As long as you keep a clear distinction between source and installed packages, just pick a strategy that works within your overall system for file organization, and use it consistently. Once you have a location to hold the source code, both and have tools that help to automate the creation of a basic package structure. We’ll use these tools in the hands-on sections of this chapter. 4.1.3 Version control Most package development never resides solely on one operating system nor with only one developer. So not only should we be using git for version control, we should be using a hosting platform such as GitHub, GitLab, Azure Repos, or the like. So the first thing we need to do is connect our local git repository to a remote repository so we can push, pull, and merge updates we make to the package. Once we have established our remote repository, we should set up a proper branching method for our work. We advise a Git flow branching strategy where: master branch is the “production” release branch. This is the main branch where the source code always reflects a production-ready state. develop branch is the main branch where the source code always reflects a state with the latest delivered development changes for the next release. Some would call this the “integration branch”. supporting branches are the branches where we do the majority of our work. These are the branches where we create new fixtures, fix bugs, improve documentation. In this branching approach, we will make updates to our package in a supporting branch, then do a pull request to merge these updates into the develop branch. Once the develop branch has enough updates to warrant a new release we then merge the develop to master with a pull request. This may seem like a lot to digest and it may seem like overkill when working on our own small prototype packages. However, this is how larger projects should be organized so adopting this approach now will make it easier when you start working on larger, group projects/packages. If you are unfamiliar with git and branching then we recommend these tutorials to get started: Understanding the GitHub flow A successful Git branching model In the hands-on sections of this chapter we’ll walk through setting up this git flow branching strategy. 4.2 Setup a virtual environment By default, every project on your system will use the same library directory to store and retrieve packages. At first glance, this may not seem like a big deal but it does matter when different projects require different versions of dependency packages. Consider the following scenario where you have two projects: Project A and Project B, both of which have a dependency on the same library, somepkg. The problem becomes apparent when we start requiring different versions of somepkg. Maybe Project A needs v1.0.0, while Project B requires the newer v2.0.0, for example. This is a real problem for both and since they can’t differentiate between versions in the library directory. So both v1.0.0 and v2.0.0 would reside in the same directory with the same name. Since packages are stored according to just their name, there is no differentiation between versions. Thus, both Project A and Project B would be required to use the same version, which is unacceptable in many cases. This is where virtual environments come into play. Virtual environments create an isolated environment for our project. This means that each project can have its own dependencies, regardless of what dependencies every other project has. This creates better reliability during the development process. In the hands-on sections of this chapter, we’ll setup and virtual environments. We consider it a best practice to always do your development work in virtual environments. To learn more about virtual environments we suggest starting with the following tutorials: Python Virtual Environments: A Primer renv: Project Environments for R 4.3 Add new functionality So we finally have our project set-up ready, now it’s time to start adding some functionality. When adding new functionality or fixing a bug, it’s important to approach it strategically. Rather than just adding or changing code, we should do it in a way that we know whether our code is successful or not. To accomplish this, we should use a test-driven development (TDD) approach. The general idea behind TDD is to follow this basic approach: Add a test: In TDD, each new feature or bug fix begins with writing a test. This test defines a function, improvements of a function, or a case in which a function results in a bug. Run test(s) and make sure the new test fails: Before writing any source code, run the new test to ensure that it fails. Write the code: The next step is to write some code that causes the test to pass. The new code written at this stage is not perfect and may, for example, pass the test in an inelegant way. That is acceptable because it will be improved and honed in Step 5. Run tests: If all test cases now pass, the programmer can be confident that the new code meets the test requirements, and does not break or degrade any existing features. If they do not, the new code must be adjusted until they do. Refactor code: Once the source code passes the test, you should spend time refactoring and cleaning it up. A growing code base can quickly get out of control. This step ensures you take the time to reduce tech debt. Repeat: Starting with another new test, the cycle is then repeated to push forward the functionality of the source code. This may seem like a lot of steps to remember but this process is rather quick and each step takes very small incremental steps forward. After implementing a few features in this manner it quickly becomes a natural approach to software development. If you are interested in learning more about the TDD philosophy we recommend the following books: The Pragramatic Programmer (Ch. 41) Clean Code (Ch. 9) Test Driven Development 4.4 Document Once your new functionality is successfully passing tests and has been refactored, you should make sure any necessary documentation is added or updated. This will include function specific documentation, module level documentation, any code in example notebooks or vignettes and the like. 4.5 Version control Lastly, we need to now save our work to our remote repository. This typically includes staging, commiting and pushing our changes. Depending on the stage of our work we may be ready to do a pull request into the main development branch. Okay, so this may seem like a lot of steps to keep track of. Often, this feels more convoluted on paper than when you are actually implementing so let’s start working with an example package to go through these steps. 4.6 example Let’s work through a simple example to illustrate how to perform the previous steps discussed for an package. We’ll create a package that has a single function. To simplify this process we’ll just reimplement existing functionality that already exists in R…calculating the mean of a vector. 4.6.1 Step 1: Check package name Although we are not going to publish this package we should still check to make sure there are no other packages that have the same name. For this example, I’m going to use the name “myfirstpkg”. We can use available::available() to check the availability of the name on CRAN, Bioconductor (another R package manager that is focused on biostats packages), and Github. It will even provide you hyperlinks to common websites that will let you know if this name is an existing abbreviation, wikipedia topic, or even in an urban dictionary along with any unexpected sentiment. In this case, we see that there are no conflicting packages on CRAN or Bioconductor but there are on Github. This is ok in this case as I don’t expect to import and use other peoples first packages! So let’s proceed. available::available(&quot;myfirstpkg&quot;, browse = FALSE) ## Urban Dictionary can contain potentially offensive results, ## should they be included? [Y]es / [N]o: ## ── myfirstpkg ────────────────────────────────────────────────────────────────── ## Name valid: ✔ ## Available on CRAN: ✔ ## Available on Bioconductor: ✔ ## Available on GitHub: ✖ ## Abbreviations: http://www.abbreviations.com/myfirstpkg ## Wikipedia: https://en.wikipedia.org/wiki/myfirstpkg ## Wiktionary: https://en.wiktionary.org/wiki/myfirstpkg ## Urban Dictionary: ## Not found. ## Sentiment:??? 4.6.2 Step 2: Create package directory and structure Now let’s create the initial package structure. There are several ways to do this but in this case I’ve set up a pre-built template that helps automate the initial structure. Open up your terminal and run: pip install cookiecutter Now go to the location that you want the package source code to live (i.e. a directory on your Desktop versus in a Packages subdirectory). In my case, I am going to keep this in a misk subdirectory: cd ~/Desktop/Workspace/Projects/misk Next, we’ll run the following command. This uses cookiecutter to create our simplified pre-built package. cookiecutter https://github.com/misk-data-science/package-template When you run this, you will be asked a series of questions such as your name, email, and package specific questions. For my package, I provided the following command responses: first_name [ex: John]: Brad last_name [ex: Smith]: Boehmke email [first.last@example.com]: bradleyboehmke@gmail.com github_username [bradleyboehmke]: bradleyboehmke package_language [r or python]: r package_name [awesome]: myfirstpkg package_short_description [short one-liner, ex: My first package]: My first package version [0.1.0]: url [https://github.com/bradleyboehmke/myfirstpkg]: Select open_source_license: 1 - MIT license 2 - BSD license 3 - ISC license 4 - Apache Software License 2.0 5 - GNU General Public License v3 6 - Not open source Choose from 1, 2, 3, 4, 5, 6 [1]: 5 The values in the brackets are the default values if you do not supply any input. For example, note how I did not enter any values for the version number or the URL. This is because 0.1.0 is nearly always a good first version number to start with. The Github URL is automatically generated so unless you choose to use a different remote the default should be a good choice. You should now have a directory with your package name in your current directory. If you use the shell command ls you should see myfirstpkg listed. Here is what my directory look likes: ls ds-packages misk-dl misk-homl myfirstpkg package-template 4.6.3 Step 3: Version control The first thing we want to do is create a remote where we’ll push our source code to (i.e. Github). In our case, we’ll use Github. First, create a new repository on GitHub. To avoid errors, do not initialize the new repository with README, license, or gitignore files since our local directory already contains these files. Now go back to your terminal and cd into the source code directory. cd myfirstpkg Next, we initialize the local package directory as a git repo and add the remote URL. This allows changes to be tracked and when we push and pull our changes it will push and pull from the URL location. We can always verify that our remote was added with git remote -v: git init . git remote add origin https://github.com/bradleyboehmke/myfirstpkg # verify remotes were added git remote -v origin https://github.com/bradleyboehmke/myfirstpkg (fetch) origin https://github.com/bradleyboehmke/myfirstpkg (push) Now let’s create our first commit so that we have a baseline (although empty) package. git add -A git commit -m &quot;create initial package structure&quot; git push --set-upstream origin master Now if you look at your Github repo you will see the master branch has your current directory contents. Recall in section 4.1.3 that we prefer to do development work with a support » develop » master branch framework. This has us doing work in a support branch and not the master or develop branch. Right now we only have a master branch established so let’s create a develop branch with git checkout -b develop and push the contents of the develop branch (which are the same as the master) to Github. git checkout -b develop git push --set-upstream origin develop Now if you look at Github you’ll notice that we have two branches in our repo: Whew 😌! We finally have our version control set up. That was a bit of work but you only need to do that once at package creation time. 4.6.4 Step 4: Setup virtual environment Before we add any new functionality to our package, let’s create a virtual environment so we can keep all our package dependencies isolated to the location we are working in. Go ahead and open up the R project in the package source code location. You can do that by clicking on the myfirstpkg.Rproj file or from the command line with: open myfirstpkg.Rproj This will open the package project within RStudio, which is where we’ll do the majority of our work from here on out. We’ll use the renv package to create a virtual environment. Using bare = TRUE will create an empty projec library (with the exception of renv. Running renv::init() uses the default bare = FALSE which will perform an automate search throughout your directory to identify required packages and automatically install them into your environment. # install.packages(&quot;renv&quot;) # install renv if necessary renv::init(bare = TRUE) This will add some hidden files and a renv/ directory to your repo. If you look inside the renv/ directory you will see that only one package exists, the renv package. The first thing we want to do is make sure we have the devtools package installed. This is the primary dev package required for package development. Running the following will install devtools into our virtual environment. If you previously installed a package that meets the version number requested, renv is smart and does a linked cache rather than install the package completely. This means if you use the latest version of devtools in many projects you won’t be needlessly installing and storing multiples of the same version. install.packages(&quot;devtools&quot;) Now let’s install all the initial packages that we will need. The DESCRIPTION file always contains a packages dependencies. By running the following, we will install all these dependencies into our environment. devtools::install_deps() The last thing we need to do is run renv::snapshot(). This saves the state of our project dependencies to a renv.lock file. That is, renv.lock holds all installed dependency packages required by your project. That way, anyone can recreate your virtual environment by running renv::restore(). renv::snapshot() Anytime you add a new dependency package make sure you run renv::snapshot() to update the renv.lock project dependency list. 4.6.5 Step 5: Add new functionality Now that our virtual environment is set up, let’s add some functionality to our package. The first thing we’ll add is a function that computes the mean of a vector. Recall that when we add new functionality we: create a new branch to do the work in, create a test that initially fails, write the code to make the test pass. So first, we’ll create a new branch, which we can just call add_mean: git checkout -b add_mean Now let’s create two new files: usethis::use_r(&quot;mean&quot;): creates a new mean.R file within the R/ directory. This is where our function will be written. usethis::use_test(&quot;mean&quot;): creates a new test-mean.R file within the tests/testthat/ directory. This is where the test ensure our function is working correctly will go. usethis::use_r(&quot;mean&quot;) usethis::use_test(&quot;mean&quot;) Later chapters will discuss ways to organize your source code within the R/ directory and your associated tests. For now, we’ll just create a new script for both. Now open up the R/mean.R file and insert a shell function. Since this function is empty it simply returns NULL but it will allow us to create and run a failing first test. my_mean &lt;- function(x) { } Now open the tests/testthat/test-mean.R file and let’s create our first test. We can always add more tests later but for the first test we just want to check for the most basic functionality. Consequently, this test is simply testing that the mean of vector containing values 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 is 5. test_that(&quot;mean of simple vectors compute accurately&quot;, { x &lt;- 0:10 expect_equal(my_mean(x), 5) }) To run our test, we need to first load our package’s function (just my_mean for now) and then execute the test. You can do this from the RStudio console with: devtools::load_all() devtools::test() ## ✓ | OK F W S | Context ## x | 0 1 | mean ## ───────────────────────────────────────────────────────────────────────────────────── ## test-mean.R:4: failure: mean of simple vectors compute accurately ## my_mean(x) not equal to 5. ## target is NULL, current is numeric ## ───────────────────────────────────────────────────────────────────────────────────── ## ## ══ Results ══════════════════════════════════════════════════════════════════════════ ## OK: 0 ## Failed: 1 ## Warnings: 0 ## Skipped: 0 You will find yourself doing this pattern often. The shortcut for devtools::load_all() is Ctrl + Shift + L (Windows &amp; Linux) or Cmd + Shift + L (macOS) and devtools::test() is Ctrl/Cmd + Shift + T. As you see above, our test is failing. So let’s start adding code to make this test pass. We know that the mean is computed as \\(m = \\frac{\\text{sum of terms}}{\\text{number of terms}}\\). Let’s update our function to account for that: my_mean &lt;- function(x) { total &lt;- sum(x) units &lt;- length(x) return(total / units) } Now running our test again we get success! devtools::test() ## ✓ | OK F W S | Context ## ✓ | 1 | mean ## ## ══ Results ══════════════════════════════════════════════════════════════════════════ ## OK: 1 ## Failed: 0 ## Warnings: 0 ## Skipped: 0 We likely want to iterate like this to make our function more robust. For example, what happens if a user passes non-numeric values or a non-vector data structure to our function? Or what happens if our vector contains NA, NaN, or Inf values? For each scenario like this we want to create a test first, make sure it fails, and then add the new functionality to our code to make our tests pass. We’ll explore this process more in chapter 7. We have empirical evidence that my_mean() works. But how can we be sure that all the moving parts of our package still work? This may seem silly to check, after such a small addition, but it’s good to establish the habit of checking this often. R CMD check, executed in the shell, is the gold standard for checking that an R package is in full working order. devtools::check() is a convenient way to run this without leaving your R session. A shortcut for devtools::check() is Ctrl/Cmd + Shift + E Also, note that this check produces rather voluminous output. The last output will list the key results and, if there are errors or warnings, it will typically point you in the right direction to resolve them. devtools::check() ## ── Building ────────────────────────────────────────────────────────────────── myfirstpkg ── ## Setting env vars: ## ● CFLAGS : -Wall -pedantic -fdiagnostics-color=always ## ● CXXFLAGS : -Wall -pedantic -fdiagnostics-color=always ## ● CXX11FLAGS: -Wall -pedantic -fdiagnostics-color=always ## ──────────────────────────────────────────────────────────────────────────────────────────── ## ✓ checking for file ‘/Users/b294776/Desktop/Workspace/Projects/misk/myfirstpkg/DESCRIPTION’ ... ## ... ## ... ## ── R CMD check results ─────────────────────────────────────────────── myfirstpkg 0.1.0 ──── ## Duration: 11.4s ## ## 0 errors ✓ | 0 warnings ✓ | 0 notes ✓ 4.6.6 Step 6: Document We now have new working functionality in our package, the last thing we want to do is properly document our function. We do this with roxygen2, which was installed in our environment when we ran devtools::install_deps(). We can add object-level documentation to our my_mean() function like this: #&#39; Mean of a vector #&#39; #&#39; @description #&#39; Computes arithmetic mean of a vector with numeric or logical values. #&#39; #&#39; @param x A numeric or logical vector. #&#39; #&#39; @return #&#39; The arithmetic mean of the values in x returned as a numeric vector of length one. #&#39; #&#39; @examples #&#39; x &lt;- 1:10 #&#39; my_mean(x) #&#39; #&#39; @export my_mean &lt;- function(x) { total &lt;- sum(x) units &lt;- length(x) return(total / units) } After adding the documentation we can run devtools::document() or (Cmd/Ctrl + Shift + D): devtools::document() ## Updating myfirstpkg documentation ## Loading myfirstpkg ## Writing my_mean.Rd ## Writing NAMESPACE ## Documentation completed Now you can run ?my_mean and you’ll see the help documentation show up in the RStudio window: After adding the documentation its best to re-run the tests and R Cmd check to ensure nothing unexpected happened while adding the documentation. Later chapters will go into the details of roxygen documentation along with other documentation we should be updating along the way (i.e. NEWS.md). 4.6.7 Step 8: Version control We now have the new functionality and documentation in place. Now we need to commit our changes, push them to Github and do a pull request to merge into the development branch of the package. Learn about writing clear and effective git messages here. git add -A git commit -m &quot;feat: add my_mean to compute arithmetic mean&quot; git push --set-upstream origin add_mean Once the changes have been pushed to Github you will notice the updated branch changes were successfully pushed. Next, select the “Compare &amp; pull request” button next to the new changes: Be sure to choose the “base: develop” option for the pull request. This will signal that we want to merge our changes in the the feature branch with the develop branch: Next we add a good summary of the pull request that signals what we added/changed and that we ran tests and checks successfully. After you add the message, go ahead and tag a friend or colleague to review your pull request. With more formalized projects we typically require that 1-2 folks have reviewed code changes in pull requests. Once all reviewers have successfully signed off on the pull request go ahead and merge it into develop. If pull requests are new to you, read more about them here: Github help docs The (written) unwritten guide to pull requests Best practices for pull requests 4.7 example Now we’ll work through a simple example to illustrate how to perform the basic workflow steps for n package. As in the previous section, we’ll create a package that has a single function…calculating the mean of a vector. 4.7.1 Step 1: Check package name Although we are not going to publish this package we should still check to make sure there are no other packages that have the same name. For this example, I’m going to use the name “myfirstpypkg”. We can use pip search to check the availability of the name on PyPI. If you followed along in last sections R example then make sure you use a different name. In this case, we see that there are no conflicting packages on PyPI! So let’s proceed. pip search myfirstpypkg 4.7.2 Step 2: Create package directory and structure Now let’s create the initial package structure. There are several ways to do this but similar to the example we’ll use a pre-built template that helps automate the initial structure. Open up your terminal. If you didn’t follow along in the last section then run the following to install cookiecutter: pip install cookiecutter Now go to the location that you want the package source code to live (i.e. a directory on your Desktop versus in a Packages subdirectory). In my case, I am going to keep this in a misk subdirectory: cd ~/Desktop/Workspace/Projects/misk Next, run the following command: cookiecutter https://github.com/misk-data-science/package-template When you run this, you will be asked a series of questions such as your name, email, and package specific questions. For my package, I provided the following command responses: first_name [ex: John]: Brad last_name [ex: Smith]: Boehmke email [first.last@example.com]: bradleyboehmke@gmail.com github_username [bradleyboehmke]: bradleyboehmke package_language [r or python]: python package_name [awesome]: myfirstpypkg package_short_description [short one-liner, ex: My first package]: My first package version [0.1.0]: url [https://github.com/bradleyboehmke/myfirstpypkg]: Select open_source_license: 1 - MIT license 2 - BSD license 3 - ISC license 4 - Apache Software License 2.0 5 - GNU General Public License v3 6 - Not open source Choose from 1, 2, 3, 4, 5, 6 [1]: 5 The values in the brackets are the default values if you do not supply any input. For example, note how I did not enter any values for the version number or the URL. This is because 0.1.0 is nearly always a good first version number to start with. The Github URL is automatically generated so unless you choose to use a different remote the default should be a good choice. You should now have a directory with your package name in your current directory. If you use the shell command ls you should see myfirstpypkg listed. Here is what my directory look likes: ls ds-packages misk-dl misk-homl myfirstpkg myfirstpypkg package-template 4.7.3 Step 3: Version control The first thing we want to do is create a remote where we’ll push our source code to (i.e. Github). In our case, we’ll use Github. First, create a new repository on GitHub. To avoid errors, do not initialize the new repository with README, license, or gitignore files since our local directory already contains these files. Now go back to your terminal and cd into the source code directory. cd myfirstpypkg Next, we initialize the local package directory as a git repo and add the remote URL. This allows changes to be tracked and when we push and pull our changes it will push and pull from the URL location. We can always verify that our remote was added with git remote -v: git init . git remote add origin https://github.com/bradleyboehmke/myfirstpypkg # verify remotes were added git remote -v origin https://github.com/bradleyboehmke/myfirstpypkg (fetch) origin https://github.com/bradleyboehmke/myfirstpypkg (push) Now let’s create our first commit so that we have a baseline (although empty) package. git add -A git commit -m &quot;create initial package structure&quot; git push --set-upstream origin master Now if you look at your Github repo you will see the master branch has your current directory contents. Recall in section 4.1.3 that we prefer to do development work with a support » develop » master branch framework. This has us doing work in a support branch and not the master or develop branch. Right now we only have a master branch established so let’s create a develop branch with git checkout -b develop and push the contents of the develop branch (which are the same as the master) to Github. git checkout -b develop git push --set-upstream origin develop Now if you look at Github you’ll notice that we have two branches in our repo: Whew 😌! We finally have our version control set up. That was a bit of work but you only need to do that once at package creation time. 4.7.4 Step 4: Setup virtual environment Before we add any new functionality to our package, let’s create a virtual environment so we can keep all our package dependencies isolated to the location we are working in. Go ahead and open up the Python project in your favorite editor. I will be using VS Code and I can open up the project with: This assumes that you have already set the project directory as the working directory. code . This will open the project, which is where we’ll do the majority of our work from here on out. We’ll use the venv package to create a virtual environment. Run the following in your terminal to create and activate the virtual environment: python -m venv venv source venv/bin/activate This will add a venv/ directory to your repo. If you look inside the venv/ directory you will see a lib/ directory that contains a couple of basic packages. Now let’s install all the initial packages that we will need. The setup.py file contains package dependencies. By running the following, we will install all these dependencies into our environment. The -e installs our empty package in an __e__ditable fashion, this means as we make updates to the package we won’t need to reinstall along the way. The &quot;.[dev]&quot; installs all development required dependencies. We’ll cover this in chapter 5. pip install -e &quot;.[dev]&quot; Whenever you are done working in your virtual environment you can run deactivate to exit out of your virtual environment. 4.7.5 Step 5: Add new functionality Now that our virtual environment is set up, let’s add some functionality to our package. The first thing we’ll add is a function that computes the mean of a vector. Recall that when we add new functionality we: create a new branch to do the work in, create a test that initially fails, write the code to make the test pass. So first, we’ll create a new branch, which we can just call add_mean: git checkout -b add_mean Now let’s create two new files: touch src/myfirstpypkg/mean.py: creates a new mean.py file within the source code directory. This is where our function will be written. touch tests/test_mean.py: creates a new test_mean.py file within the tests/ directory. This is where the test to ensure our function is working correctly will go. touch src/myfirstpypkg/mean.py touch tests/test_mean.py Later chapters will discuss ways to organize your source code within the src/ directory and your associated tests. For now, we’ll just create a new script for both. Now open up the src/myfirstpypkg/mean.py file and insert a shell function. pass is a null operation – when it’s executed, nothing happens and consequently the function will return None. This allows us to create and run a failing first test. def my_mean(x): pass Now open the tests/test_mean.py file and let’s create our first test. We can always add more tests later but for the first test we just want to check for the most basic functionality. Consequently, this test is simply testing that the mean of values 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 is 5. from myfirstpypkg.mean import my_mean def test_my_mean(): x = range(0, 11) assert my_mean(x) == 5 Now we can run our tests by executing pytest at the command line: pytest ===================================== test session starts ====================================== platform darwin -- Python 3.7.3, pytest-5.4.2, py-1.8.1, pluggy-0.13.1 rootdir: /Users/b294776/Desktop/Workspace/Projects/misk/myfirstpypkg, inifile: setup.cfg, testpaths: tests/ collected 1 item tests/test_mean.py F [100%] =========================================== FAILURES =========================================== _________________________________________ test_my_mean _________________________________________ def test_my_mean(): x = range(0, 11) &gt; assert my_mean(x) == 5 E assert None == 5 E + where None = my_mean(range(0, 11)) tests/test_mean.py:5: AssertionError =================================== short test summary info ==================================== FAILED tests/test_mean.py::test_my_mean - assert None == 5 ====================================== 1 failed in 0.09s ======================================= As you see above, our test is failing. So let’s start adding code to make this test pass. We know that the mean is computed as \\(m = \\frac{\\text{sum of terms}}{\\text{number of terms}}\\). Let’s update our function to account for that: def my_mean(x): total = sum(x) units = len(x) return total / units Now running our test again we get success! pytest ========================================= test session starts ========================================= platform darwin -- Python 3.7.3, pytest-5.4.2, py-1.8.1, pluggy-0.13.1 rootdir: /Users/b294776/Desktop/Workspace/Projects/misk/myfirstpypkg, inifile: setup.cfg, testpaths: tests/ collected 1 item tests/test_mean.py . [100%] ========================================== 1 passed in 0.01s ========================================== We likely want to iterate like this to make our function more robust. For example, what happens if a user passes non-numeric values or a non-list data structure to our function? Or what happens if our list contains None, np.nan, or or some other missing value representation values? For each scenario like this we want to create a test first, make sure it fails, and then add the new functionality to our code to make our tests pass. We’ll explore this process more in chapter 7. We have empirical evidence that my_mean() works so now let’s talk about documentation. 4.7.6 Step 6: Document We now have new working functionality in our package, the last thing we want to do is properly document our function. We do this with docstrings. We can add object-level documentation to our my_mean() function like this: def my_mean(x): &quot;&quot;&quot; Mean of a vector Computes arithmetic mean of a vector with numeric or logical values. Parameters ---------- x A numeric or logical list. Returns ------- The arithmetic mean of the values in x returned as a numeric vector of length one. Examples -------- &gt;&gt;&gt; x = range(0, 11) ... my_mean(x) &quot;&quot;&quot; total = sum(x) units = len(x) return total / units After adding the documentation we can now get various help documentation on the function. For example, hovering over the function in my editor shows the following: After adding the documentation its best to re-run the tests to ensure nothing unexpected happened while adding the documentation. Later chapters will go into the details of docstrings along with other documentation we should be updating along the way (i.e. module level docstrings, CHANGELOG.md). 4.7.7 Step 7: Version control We now have the new functionality and documentation in place. Now we need to commit our changes, push them to Github and do a pull request to merge into the development branch of the package. Learn about writing clear and effective git messages here. git add -A git commit -m &quot;feat: add my_mean to compute arithmetic mean&quot; git push --set-upstream origin add_mean Once the changes have been pushed to Github you will notice the updated branch changes were successfully pushed. Next, select the “Compare &amp; pull request” button next to the new changes: Be sure to choose the “base: develop” option for the pull request. This will signal that we want to merge our changes in the the feature branch with the develop branch: Next we add a good summary of the pull request that signals what we added/changed and that we ran tests and checks successfully. After you add the message, go ahead and tag a friend or colleague to review your pull request. With more formalized projects we typically require that 1-2 folks have reviewed code changes in pull requests. Once all reviewers have successfully signed off on the pull request go ahead and merge it into develop. If pull requests are new to you, read more about them here: Github help docs The (written) unwritten guide to pull requests Best practices for pull requests "],
["metadata.html", "5 Package Metadata 5.1 Name and package description 5.2 Author and contact info 5.3 Dependencies 5.4 Versioning 5.5 License 5.6 Project source 5.7 Other 5.8 example 5.9 example", " 5 Package Metadata Every package requires important metadata about the package. This file will declare various information such as package name, description, dependencies, author(s), contact information and more. This chapter covers the metadata information that is either required or should be included in both and packages along with the key files to supply this information. First, we’ll talk about the metadata to include and then the last two sections will walk through the and files that hold this info. 5.1 Name and package description Name, title and description information help describe what the package does. Both and have some general guidelines required for each of these fields such as the number of characters. However, the intent is often the same: Name is the name of the package, A shorter, one line description of the package provides, A longer, multi-line description of the package. This is the elevator pitch of the key things that your package does and how important it is to others. 5.2 Author and contact info Packages require at least the primary author to be listed along with their email contact information. You can optionally provide additional authors and contributors along with their contact info. 5.3 Dependencies Most packages have dependencies. Moreover, packages can have different types of dependencies: Language version dependency: Sometimes our package relies on certain language features that are only available in certain versions. For example, if you use f-strings in a Python package than your package depends on using Python v3.6 or later. Required package dependencies: Often our package uses other third party packages to simplify tasks. We may use dplyr or pandas to simplify data frame manipulations. We need to capture any required packages used by our source code to make sure anyone using our package also has these required packages installed on their operating system (OS). Suggested package dependencies: Sometimes your package leverages third party packages but doesn’t strictly require them to provide its fundamental capabilities. This may include packages that provide example datasets, running tests, building documentation, etc. We can usually specify these packages in a way that doesn’t enforce installation onto a users OS but provides them the option to install them if necessary. Developer dependencies: Developers often use certain packages for enabling syntax styling, pre-commit hooks and other developer environment requirements. 5.4 Versioning There is a wide array of options when it comes to software versioning; however, we advise using a Semantic Versioning approach. Semantic versioning follows a &lt;MAJOR&gt;.&lt;MINOR&gt;.&lt;PATCH&gt; numbering approach (i.e. 0.9.1, 1.4.0). With this approach, you increment certain parts of a version number depending on the changes made: &lt;MAJOR&gt; version when you make incompatible API changes. This signals that your updates will likely effect many users and will cause breaking changes to users’ prior code. &lt;MINOR&gt; version when you add functionality in a backwards compatible manner. This often includes adding a new feature that does not effect the existing code base. &lt;PATCH&gt; version when you make backwards compatible bug fixes. You may also see in-development packages using a fourth component called the development version (i.e. 1.0.0.9000). Using this development number makes it easy to see if a package is released or in-development and the use of the fourth place means that you’re not limited to what the next version will be. Unfortunately, determining the right version number is not always an exact science. For example, if you make an API-incompatible change to a rarely-used part of your code, it may not deserve a major number change. But if you fix a bug that many people depend on, it will feel like an API breaking change. Use your best judgement. Packages often start with a version number 0.1.0 and slowly increment as they mature. A version of 1.0.0 typically indicates that your package is feature complete with a stable API. 5.5 License The license field states who can use your package. The License field can be either a standard abbreviation for an open source license, like GPL-2 or BSD, or a pointer to a file containing more information, file LICENSE. The license is really only important if you’re planning on releasing your package or you may need a proprietary license for packages built within your organization. There are several open source software licenses to choose from. A few of the more common ones include: MIT: This is a simple and permissive license. It lets people use and freely distribute your code subject to only one restriction: the license must always be distributed with the code. GPL-2 or GPL-3: These are “copy-left” licenses. This means that anyone who distributes your code in a bundle must license the whole bundle in a GPL-compatible way. Additionally, anyone who distributes modified versions of your code (derivative works) must also make the source code available. GPL-3 is a little stricter than GPL-2, closing some older loopholes. CC0: It relinquishes all your rights on the code and data so that it can be freely used by anyone for any purpose. This is sometimes called putting it in the public domain, a term which is neither well-defined nor meaningful in all countries. If you’d like to learn more about other common licenses, Github’s choosealicense.com is a good place to start. Another good resource is https://tldrlegal.com/, which explains the most important parts of each license. 5.6 Project source It is common to include URLs to direct users to: Where the source code resides (i.e. Github repo) Where to post bugs, feature requests, etc. (i.e. Github issues) We may also want to point people to a package documentation website, the changelog, or other URLs that host important package information. 5.7 Other As you’ll see in the next couple sections, there are additional types of metadata that we can include such as deploying data or other files (i.e. LICENSE) with you package. However, the items listed in the previous section are the primary forms of metadata that we want to ensure we include. 5.8 example The DESCRIPTION file is the main file used to capture metadata for your package. If you look at your package’s DESCRIPTION file you will see that several items are already filled out. Package: myfirstpkg Title: My First Package Version: 0.1.0 Authors@R: person(&quot;Brad&quot;, &quot;Boehmke&quot;, email = &quot;bradleyboehmke@gmail.com&quot;, role = c(&quot;aut&quot;, &quot;cre&quot;)) Description: Provide a longer description of what the package does. This is the place to give your elevator pitch of how great this package is and how important it is to others. URL: https://github.com/bradleyboehmke/myfirstpkg BugReports: https://github.com/bradleyboehmke/myfirstpkg/issues License: file LICENSE Encoding: UTF-8 LazyData: true Depends: R (&gt;= 2.10) Suggests: testthat Roxygen: list(markdown = TRUE) RoxygenNote: 7.1.0 A couple items to note: Title is the one line description of the package you supplied when creating the package structure. It should be plain text, title case, and NOT end in a period. If submitting to CRAN, this will be truncated to 65 characters. So depending on your original input you may want to adjust the Title to ensure it meets these requirements. Your Author information has been included but if you are working with multiple people you may want to include more authors which can look like this: Authors@R: c( person(&quot;John&quot;, &quot;Doe&quot;, email = &quot;john.doe@example.com&quot;, role = &quot;cre&quot;), person(&quot;Jane&quot;, &quot;Doe&quot;, email = &quot;jane.doe@examplecom&quot;, role = &quot;aut&quot;)) Note that there are various roles authorship can have. The main ones include: cre: the creator or maintainer, the person to contact if there are problems. aut: authors, those who have made significant contributions to the package. ctb: contributors, those who have made smaller contributions, like patches. cph: copyright holder. This is used if the copyright is held by someone other than the author, typically a company (i.e. the author’s employer). Description is more detailed than the title. You can use multiple sentences but you are limited to one paragraph. If your description spans multiple lines (and it should!), each line must be no more than 80 characters wide. Indent subsequent lines with 4 spaces. License points to the LICENSE file automatically created based on the license you specified. Encoding is if you use any non-ASCII characters in the DESCRIPTION file, you must also specify an encoding. There are three main encodings that work on all platforms: latin1, latin2 and UTF-8 (by far the most common). LazyData makes it easier to access data in your package. Because it’s important, it’s included in the basic template even though you may not share data through your package. 5.8.1 Dependencies Currently in our DESCRIPTION file we specify: Depends: R (&gt;= 2.10) Suggests: testthat Depends states that our package depends on the users version of R to be 2.10 or greater. Think very carefully before increasing to a more restrictive version of R. As you add more sophisticated functionality to your package you, as the developer, need to think about whether or not those functionalities will continue to work on all versions of R &gt;= 2.10 or if you need to bump the version number to, say, 3.0. Suggests states that our package leverages the testthat package but it is not required for basic functionality. In fact, testthat is only used to run the tests for our package so a regular user of our package does not need testthat to use my_mean(). Often, we will need to add new dependencies to our package. For example, say one of our functions uses the dplyr and ggplot2 packages and one our tests uses the purrr package. Then, our package’s functionality depends on dplyr and ggplot2 but purrr is not a hard requirement. We would add the required package dependencies under Imports and the non-hard requirements under Suggests: Generally you will only put the R version under Depends and keep all package requirements under Imports. Depends: R (&gt;= 2.10) Imports: dplyr, ggplot2 Suggests: purrr, testthat You can easily add new packages to the Imports and Suggests fields with: usethis::use_package(“pkg_name”) usethis::use_package(“pkg_name”, “Suggests”) Also, you can require specific versions of a package by specifying the version in parentheses after the package name: Imports: ggvis (&gt;= 0.2), dplyr (&gt;= 0.3.0.1) Suggests: MASS (&gt;= 7.3.0) 5.8.2 Exercises Check out the LICENSE file in your package. Fill out the Description field for your package. Add dplyr as a required package dependency. Add purrr as a suggested package dependency. Run devtools::check() to make sure the package builds successfully. 5.9 example The setup.py file is the main file used to capture metadata for your package and configures your package for distribution. The setup() function provides the main functionality. If you look at your package’s setup.py file you will see that several items are already filled out. #!/usr/bin/env python &quot;&quot;&quot;Setup, configuration, and metadata file for the myfirstpypkg package.&quot;&quot;&quot; from setuptools import find_packages from setuptools import setup install_requires = [] doc_requires = [&quot;sphinx&quot;, &quot;sphinx_rtd_theme&quot;, &quot;sphinxcontrib.napoleon&quot;] test_requires = [&quot;pytest&quot;] dev_requires = [&quot;flake8&quot;, &quot;mypy&quot;] + doc_requires + test_requires setup( name=&quot;myfirstpypkg&quot;, version=&quot;0.1.0&quot;, license=&quot;GNU General Public License v3&quot;, description=&quot;My first package&quot;, url=&quot;https://github.com/bradleyboehmke/myfirstpypkg&quot;, author=&quot;Brad Boehmke&quot;, author_email=&quot;bradleyboehmke@gmail.com&quot;, package_dir={&quot;&quot;: &quot;src&quot;}, packages=find_packages(where=&#39;src&#39;), python_requires=&#39;&gt;=3.6&#39;, install_requires=install_requires, extras_require={&quot;docs&quot;: doc_requires, &quot;tests&quot;: test_requires, &quot;dev&quot;: dev_requires}, test_suite=&quot;tests&quot;, include_package_data=True, project_urls={ &#39;Source&#39;: &quot;https://github.com/bradleyboehmke/myfirstpypkg&quot;, &#39;Bug Reports&#39;: &quot;https://github.com/bradleyboehmke/myfirstpypkg/issues&quot;, }, ) A couple items to note: description is a one-line description or tagline of what your project does but does not require title-case or have a strict character length restriction. Note that you can also supply a longer, multi-line description with a long_description parameter. package_dir and packages points to where the package is located. In our case we have our package in the src/ subdirectory so we need to specify that is where it is located. test_suite simply tells pytest where to look to find and run our tests. include_package_data is used when you have data you want to deploy with your package. 5.9.1 Dependencies A common theme you will see is specifying all package requirements in a list and then supplying them to setup() parameters as we are doing in our current setup.py: python_requires is where you need to specify the version of Python required for your package. When a user tries to install your package pip install will check that the user’s Python version meets this requirement and refuse to install the project if the version does not match. install_requires is where any required package dependencies would be added. In this case, our initial package has no requirements but if we added functionality that requires numpy for example, then we would include numpy in the currently empty install_requires list. extras_require is where any additional “supporting” packages would go. These are packages that are not required for normal use but commonly required to run tests, build supporting documentation, and execute other common developer activities. Users can install these “extras” by running pip install pkgname[dev]. When you are developing you will often do the following the activate your virtual environment, install the package in an editable fashion, and ensure all developer required packages are installed in your environment: bash source venv/bin/activate pip install -e . &quot;.[dev]&quot; 5.9.2 Exercises Check out the LICENSE file in your package. Create a long_description field for your package. Add numpy as a required package dependency. Add black as a developer suggested package dependency. Activate your virtual environment, install your package in editable mode, ensure all developer dependencies are installed and rerun your test(s). "],
["code.html", "6 Source Code 6.1 Organization 6.2 External vs internal 6.3 example 6.4 example", " 6 Source Code An important principle in any project is how to manage the source code. In this chapter, you’ll learn about the directories that hold the and package source code and some general tips for organizing source code functionality. We’ll also add some new functionality to our package to demonstrate our thoughts. 6.1 Organization Organizing your source code provides many benefits such as: making the intentions of the code obvious, making it easy for others to contribute, making it easy for you to maintain, making it easy to debug, making it easy to expand. There are very few strict requirements in how you organize your code but what follows are general best practices. 6.1.1 Individual units “Functions should do one thing. They should do it well. They should do it only.” - Robert Martin Individual units of functionality (i.e. functions, methods, classes) should be small. How small? That’s the magic question 🤷. Individual units of functionality should not require significant scrolling in your editor. They should be very clear regarding the intention and functionality they are providing. And they should only “do one thing”. One way to know if a function is doing more than one thing is if you can extract another function from it with a name that is not merely a restatement of its implementation. So far our package has only one simple function; however, we typically build our packages to be more comprehensive and complex. Organizing this expansion is important. There are two main ways our code expands: breadth: we add more functionality but not necessarily building onto existing functionality, aggregation: we continue building onto existing functionality to create layers of abstraction. 6.1.2 Expanding code breadth Expanding code breadth is easier to maintain. For our example package that currently has a my_mean() function, this could include adding new functions such as my_median() and my_mode(). When expanding code breadth the main thing you should consider is where to put the new functionality. Grouping like functionality into one file is good. For example, since my_mean(), my_median() and my_mode() are all forms of central tendencies we may put them in the same file while functions with other purposes (i.e. deviations) may go into a different file. While you’re free to arrange functions into files as you wish, the two extremes are bad: don’t put all functions into one file and don’t put each function into its own separate file. (It’s OK if some files only contain one function, particularly if the function is large 🛑 or has a lot of documentation.). 6.1.3 Aggregating functionality Often, we write code that builds on top of each other. This is known as creating higher levels of abstraction. For example, say we wanted to create a function that computes the z-score, which uses the mean and standard deviations (\\(z=\\frac{x - \\mu}{\\sigma}\\)). This is a higher level of abstraction and we should write our code in such a way that: our code reads like a top-down narrative, functionality is abstracted away and grouped at similar levels of abstraction. If your code still fits into one file, we want the code to read like a top-down narrative where the highest level of abstraction is exposed first followed by the next level of abstraction. This means your highest abstracted function should be at the top of the .R or .py script and then as you scroll down functions lower level functions that provide supporting help should be listed. For example, a simple file that holds functionality to compute the z-score would look like: # highest abstracted level def z_score(): pass # next layer of abstractoin def my_mean(): pass def my_sd(): pass # lowest level of abstraction def validate_input(): pass If your code grows signicantly then you want to separate functionality into separate files but still group functions based on similar levels of abstraction. 6.1.4 Naming is important Naming is important but as our source code grows it becomes even moreso. Here are some good naming tips: If a file contains a single function, give the file the same name as the function. If a file contains multiple related functions, give it a concise, but descriptive name. For example, we could group my_mean(), my_median() and my_mode() together into a file named central_tendencies. Sometimes you have many helper functions in your source code that all support one primary user facing API functionality. Put the user-facing API function/class into a file named main or main_api. Many times people create a general utils file to hold general utility functions. This is not advised. Always try to find a proper home and name for all supporting functions. This is a great read explaining why. Deprecated functions should live in a file or directory that makes it obvious they are deprecated (i.e. prefix file name with deprec-). 6.2 External vs internal When developing packages, we often build functions with two main purposes: External use: functions that are designed to be used by the end-user. This is the primary purpose of writing a package, to make some functionality easier for an end-user. Internal use: functions that are designed to help you, the developer, write efficient and effect code. Internal functions are usually not intended for external use by end-users. With both and you have the ability to make your functions be either externally or internally focused. In the sections that follow we will illustrate how but it is important that you apply the same rules to both external and internal functions - document and test all your functions. Although not a requirement this will make your life and other developer’s lives that want to contribute much easier. 6.3 example For an package, all source code goes in the R/ directory and you cannot have subdirectories1. Let’s add some functionality to our package to illustrate some points from our previous discussion: add an internally-focused function that validates the user inputs, add breadth to our package by adding additional summary statistics computations, add aggregation to our package by adding a z-score computation that leverages other functions within our package. To simplify, we’ll show the final functions and tests added rather than illustrate every step of the test-driven development process. 6.3.1 Setup Before we start adding new functionality, let’s make sure the current code base is ready. Open up your R project, switch to the develop branch and make sure it is current with your remote repo: git checkout develop git pull Now let’s create a new branch to add this chapter’s new functionality. Usually you name the branch after the new functionality that you’re adding or a Github issue that you are addressing. In our case we can name the branch “ch6” since it’s related to this chapter. git checkout -b ch6 6.3.2 Internal function First, we’ll add an internally-focused function that validates the user inputs. Since we may continue to expand our package and add more validation procedures, we typically create a validation.R file to hold these functions. Go ahead and create the test and .R file: usethis::use_test(&quot;validation&quot;) usethis::use_r(&quot;validation&quot;) Place the following in the test-validation.R test file: test_that(&quot;inputs are a numeric vector&quot;, { expect_error(validate_numeric_vector(&quot;a&quot;)) expect_error(validate_numeric_vector(factor(1, 2, 3))) expect_error(validate_numeric_vector(list(1, 2, 3))) expect_silent(c(1, 2, 3)) expect_silent(c(TRUE, FALSE)) }) and the following in the validation.R source code file: #&#39; Validate numeric vector input #&#39; #&#39; @description #&#39; Checks that an in put is a vector that contains numeric inputs or #&#39; logical values that can be coerced to numeric values.. #&#39; #&#39; @param x A numeric or logical vector. #&#39; #&#39; @return #&#39; Raises exception if input is not a numeric or logical vector; otherwise #&#39; provides a silent return. #&#39; #&#39; @examples #&#39; x &lt;- 1:10 #&#39; myfirstpkg:::validate_numeric_vector(x) #&#39; #&#39; @keywords internal validate_numeric_vector &lt;- function(x) { stopifnot(is.atomic(x) || is.logical(x), is.numeric(x)) } Three important items to note in the above: We used the @keywords internal tag instead of @export as we did in chapter 4. Only functions that are documented with @export are made explicitly visible to the end user. Using @keywords internal instead of @export signals that this function is for internal use only. Internal functions are still accessible to end users but they must use the triple ::: syntax - myfirstpkg:::validate_numeric_vector(). When including examples for internal functions you need to use the triple ::: syntax - myfirstpkg:::validate_numeric_vector() otherwise you will get an error when you run devtools::check(). Even though this is an internal function, we still document it as normal. This isn’t required but it helps us and contributing developers understand the purpose of the function. Remember, as we add new code we always want to be running the tests. load new functionality: devtools::load_all() or Cmd/Ctrl + Shift + L test new functionality: devtools::test() or Cmd/Ctrl + Shift + T document new functionality: devtools::document() or Cmd/Ctrl + Shift + D Now before adding any new functionality, let’s add this validation function to our existing my_mean() function. Your my_mean() should look like: my_mean &lt;- function(x) { validate_numeric_vector(x) total &lt;- sum(x) units &lt;- length(x) return(total / units) } 6.3.3 Adding breadth Next, let’s add a new summary statistic to our collection. For now, we’ll store this summary statistic in the same file but in the future if this file became too large we may look to refactor and split up the centralized organization. Let’s rename the original mean.R file to summary-stats.R and also rename the associated test file to test-summary-stats.R. It is common to rename files and functions as you begin developing a package since you are feeling out what the best design and organization will be but as your package matures this will happen less frequently. Now we’ll add a function that computes the standard deviation. Add the following to the test-summary-stats.R file: test_that(&quot;standard deviation of simple vector computes accurately&quot;, { x &lt;- 1:3 expect_equal(my_sd(x), 1) }) and add the following to the summary-stats.R file in the R/ directory: #&#39; Standard deviation of a vector #&#39; #&#39; @description #&#39; Computes standard deviation of a vector with numeric or logical values. #&#39; #&#39; @param x A numeric or logical vector. #&#39; #&#39; @details #&#39; The denominator n - 1 is used which gives an unbiased estimator of the #&#39; (co)variance for i.i.d. observations. #&#39; #&#39; @return #&#39; The standard deviation of the values in x returned as a numeric vector of #&#39; length one. #&#39; #&#39; @examples #&#39; x &lt;- 1:10 #&#39; my_sd(x) #&#39; #&#39; @export my_sd &lt;- function(x) { validate_numeric_vector(x) squared_diff &lt;- (x - my_mean(x))^2 total &lt;- sum(squared_diff) units &lt;- length(x) - 1 return(sqrt(total / units)) } 6.3.4 Adding aggregation Last, we’ll add a new summary statistics, the z-score, that leverages the my_mean and my_sd functions. Since this is adding onto our level of abstraction we’ll place this at the top of our R/summary_stats.R file. Add the following to the test-summary-stats.R file: test_that(&quot;z-score of simple vector computes accurately&quot;, { x &lt;- 1:3 expected &lt;- c(-1, 0, 1) expect_equal(z_score(x), expected) }) and add the following to the summary-stats.R file in the R/ directory: #&#39; Z-score of a vector #&#39; #&#39; @description #&#39; Computes z-score of a vector with numeric or logical values. #&#39; #&#39; @param x A numeric or logical vector. #&#39; #&#39; @return #&#39; The z-score of each value in x returned as a numeric vector of #&#39; with equal length as the input x vector. #&#39; #&#39; @examples #&#39; x &lt;- 1:3 #&#39; z_score(x) #&#39; #&#39; @export z_score &lt;- function(x) { return((x - my_mean(x)) / my_sd(x)) } Our summary-stats.R file should now include three functions in a top-down approach: #&#39; Z-score of a vector #&#39; #&#39; @description #&#39; Computes z-score of a vector with numeric or logical values. #&#39; #&#39; @param x A numeric or logical vector. #&#39; #&#39; @return #&#39; The z-score of each value in x returned as a numeric vector of #&#39; with equal length as the input x vector. #&#39; #&#39; @examples #&#39; x &lt;- 1:3 #&#39; z_score(x) #&#39; #&#39; @export z_score &lt;- function(x) { return((x - my_mean(x)) / my_sd(x)) } #&#39; Standard deviation of a vector #&#39; #&#39; @description #&#39; Computes standard deviation of a vector with numeric or logical values. #&#39; #&#39; @param x A numeric or logical vector. #&#39; #&#39; @details #&#39; The denominator n - 1 is used which gives an unbiased estimator of the #&#39; (co)variance for i.i.d. observations. #&#39; #&#39; @return #&#39; The standard deviation of the values in x returned as a numeric vector of #&#39; length one. #&#39; #&#39; @examples #&#39; x &lt;- 1:10 #&#39; my_sd(x) #&#39; #&#39; @export my_sd &lt;- function(x) { validate_numeric_vector(x) squared_diff &lt;- (x - my_mean(x))^2 total &lt;- sum(squared_diff) units &lt;- length(x) - 1 return(sqrt(total / units)) } #&#39; Mean of a vector #&#39; #&#39; @description #&#39; Computes arithmetic mean of a vector with numeric or logical values. #&#39; #&#39; @param x A numeric or logical vector. #&#39; #&#39; @return #&#39; The arithmetic mean of the values in x returned as a numeric vector of length one. #&#39; #&#39; @examples #&#39; x &lt;- 1:10 #&#39; my_mean(x) #&#39; #&#39; @export my_mean &lt;- function(x) { validate_numeric_vector(x) total &lt;- sum(x) units &lt;- length(x) return(total / units) } And our test-summary-stats.R file should look like: test_that(&quot;z-score of simple vector computes accurately&quot;, { x &lt;- 1:3 expected &lt;- c(-1, 0, 1) expect_equal(z_score(x), expected) }) test_that(&quot;standard deviation of simple vector computes accurately&quot;, { x &lt;- 1:3 expect_equal(my_sd(x), 1) }) test_that(&quot;mean of simple vector computes accurately&quot;, { x &lt;- 0:10 expect_equal(my_mean(x), 5) }) 6.3.5 Final checks &amp; version control Now before we commit our changes to git, let’s make sure everything is loaded and documented and passes our tests and checks: document package functionality: devtools::document() or Cmd/Ctrl + Shift + D load package functionality: devtools::load_all() or Cmd/Ctrl + Shift + L test package functionality: devtools::test() or Cmd/Ctrl + Shift + T R Cmd check package functionality: devtools::check() or Cmd/Ctrl + Shift + E As long as everything is passing, we can now commit our changes, push to Github and then do a pull request to incorporate our changes from our current working branch to the develop branch. git add -A git commit -m &#39;feat: add new validation &amp; summary stats &gt; Add validation function to ensure proper numeric vector input. &gt; Add summary stat functions to compute standard deviation and z-score.&#39; git push --set-upstream origin ch6 6.4 example For a package, all source code goes in the src/pkgname/ directory. Unlike packages, you can have subdirectories and submodules in packages. However, for simplicity, we’ll just include all source code at the src/pkgname/ directory level. Let’s add some functionality to our package to illustrate some points from our previous discussion. We’ll take the same approach as in the example section and: add an internally-focused function that validates the user inputs, add breadth to our package by adding additional summary statistics computations, add aggregation to our package by adding a z-score computation that leverages other functions within our package. To simplify, we’ll show the final functions and tests added rather than illustrate every step of the test-driven development process. 6.4.1 Setup Before we start adding new functionality, let’s make sure the current code base is ready. Open up your Python project, activate your virtual environment, switch to the develop branch and make sure it is current with your remote repo: git checkout develop git pull Now let’s create a new branch to add this chapter’s new functionality. Usually you name the branch after the new functionality that you’re adding or a Github issue that you are addressing. In our case we can name the branch “ch6” since it’s related to this chapter. git checkout -b ch6 6.4.2 Internal function First, we’ll add an internally-focused function that validates the user inputs. Since we may continue to expand our package and add more validation procedures, we typically create a validation.R file to hold these functions. Go ahead and create the test and .py file: touch tests/test_validation.py touch src/myfirstpypkg/validation.py Place the following in the test_validation.py test file: from myfirstpypkg.validation import _validate_numeric_sequence import pytest def test_validate_sequence_numeric(): assert _validate_numeric_sequence(range(10)) == None with pytest.raises(TypeError): _validate_numeric_sequence(list(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;)) def test_validate_sequence_type(): with pytest.raises(TypeError): _validate_numeric_sequence({}) and the following in the validation.py source code file: from collections import Sequence def _validate_numeric_sequence(x): &quot;&quot;&quot; Validate numeric sequence input Checks that an in put is a sequence that contains numeric inputs or logical values that can be coerced to numeric values. Parameters ---------- x A numeric or logical vector. Returns ------- None Raises ------ TypeError If `x` is not a sequence of type float, int or bool. Examples -------- x = range(10) _validate_numeric_sequence(x) &quot;&quot;&quot; if not isinstance(x, (Sequence, float, int, bool)): raise TypeError(&quot;`x` must be a sequence of type float, int, or bool.&quot;) Two important items to note in the above: We start the function with an underscore _validate.... In Python, we cannot hide internal functions from end-users; however, it is Pythonic to start all functions designed for internal use with an underscore. Even though this is an internal function, we still document it as normal. This isn’t required but it helps us and contributing developers understand the purpose of the function. Remember, as we add new code we always want to be running the tests with pytest. Now before adding any new functionality, let’s add this validation function to our existing my_mean() function. Your mean.py file should look like below. Note that we use a relative import to import _validate_numeric_sequence from the validation.py module. from .validation import _validate_numeric_sequence def my_mean(x): &quot;&quot;&quot; Mean of a vector Computes arithmetic mean of a vector with numeric or logical values. Parameters ---------- x A numeric or logical list. Returns ------- The arithmetic mean of the values in x returned as a numeric vector of length one. Examples -------- &gt;&gt;&gt; x = range(0, 11) ... my_mean(x) &quot;&quot;&quot; _validate_numeric_sequence(x) total = sum(x) units = len(x) return total / units 6.4.3 Adding breadth Next, let’s add a new summary statistic to our collection. For now, we’ll store this summary statistic in the same file but in the future if this file became too large we may look to refactor and split up the centralized organization. Let’s rename the original mean.py file to summary_stats.py and also rename the associated test file to test_summary_stats.py. It is common to rename files and functions as you begin developing a package since you are feeling out what the best design and organization will be but as your package matures this will happen less frequently. Now we’ll add a function that computes the standard deviation. Update your test_summary_stats.py file to look like: from myfirstpypkg.summary_stats import my_mean from myfirstpypkg.summary_stats import my_sd def test_my_sd(): x = [1, 2, 3] assert my_sd(x) == 1 def test_my_mean(): x = range(0, 11) assert my_mean(x) == 5 and add the following to the summary_stats.py file in the src/myfirstpypkg/ directory: from math import sqrt def my_sd(x): &quot;&quot;&quot; Standard deviation of a sequence Computes standard deviation of a vector with numeric or logical values. The denominator `units = len(x) - 1` is used which gives an unbiased estimator of the (co)variance for i.i.d. observations. Parameters ---------- x A numeric or logical sequence. Returns ------- The standard deviation of the values in x returned as a numeric value of length one. Examples -------- &gt;&gt;&gt; x = [1, 2, 3] ... my_sd(x) &quot;&quot;&quot; _validate_numeric_sequence(x) mu = my_mean(x) squared_diff = [(i - mu)**2 for i in x] total = sum(squared_diff) units = len(x) - 1 return(sqrt(total / units)) 6.4.4 Adding aggregation Last, we’ll add a new summary statistics, the z-score, that leverages the my_mean and my_sd functions. Since this is adding onto our level of abstraction we’ll place this at the top of our src/myfirstpypkg/summary_stats.py file. Add a z-score test to the test_summary_stats.py file: def test_z_score(): x = [1, 2, 3] expected = [-1, 0, 1] assert z_score(x) == expected and add the following to the summary_stats.py file in the src/myfirstpypkg/ directory: def z_score(x): &quot;&quot;&quot; Z-score of a sequence Computes the z-score of a sequence with numeric or logical values. Parameters ---------- x A numeric or logical sequence. Returns ------- The z-score for each value in x as a list. Examples -------- &gt;&gt;&gt; x = [1, 2, 3] ... z_score(x) &quot;&quot;&quot; mu = my_mean(x) sd = my_sd(x) return [((i - mu) / sd) for i in x] Our summary_stats.py file should now include three functions in a top-down approach: from .validation import _validate_numeric_sequence from math import sqrt def z_score(x): &quot;&quot;&quot; Z-score of a sequence Computes the z-score of a sequence with numeric or logical values. Parameters ---------- x A numeric or logical sequence. Returns ------- The z-score for each value in x as a list. Examples -------- &gt;&gt;&gt; x = [1, 2, 3] ... z_score(x) &quot;&quot;&quot; mu = my_mean(x) sd = my_sd(x) return [((i - mu) / sd) for i in x] def my_sd(x): &quot;&quot;&quot; Standard deviation of a sequence Computes standard deviation of a sequence with numeric or logical values. The denominator `units = len(x) - 1` is used which gives an unbiased estimator of the (co)variance for i.i.d. observations. Parameters ---------- x A numeric or logical sequence. Returns ------- The standard deviation of the values in x returned as a numeric value of length one. Examples -------- &gt;&gt;&gt; x = [1, 2, 3] ... my_sd(x) &quot;&quot;&quot; _validate_numeric_sequence(x) mu = my_mean(x) squared_diff = [(i - mu)**2 for i in x] total = sum(squared_diff) units = len(x) - 1 return(sqrt(total / units)) def my_mean(x): &quot;&quot;&quot; Mean of a sequence Computes arithmetic mean of a sequence with numeric or logical values. Parameters ---------- x A numeric or logical sequence. Returns ------- The arithmetic mean of the values in x returned as a numeric value of length one. Examples -------- &gt;&gt;&gt; x = range(0, 11) ... my_mean(x) &quot;&quot;&quot; _validate_numeric_sequence(x) total = sum(x) units = len(x) return total / units And our test_summary_stats.py file should look like: from myfirstpypkg.summary_stats import my_mean from myfirstpypkg.summary_stats import my_sd from myfirstpypkg.summary_stats import z_score def test_z_score(): x = [1, 2, 3] expected = [-1, 0, 1] assert z_score(x) == expected def test_my_sd(): x = [1, 2, 3] assert my_sd(x) == 1 def test_my_mean(): x = range(0, 11) assert my_mean(x) == 5 6.4.5 Simplify user access With packages, users access objects with a module namespace approach. This means, since our z_score() function is located at: . └── src/myfirstpypkg └── summary_stats.py When they use our package they would have to access this function with one of the following: import myfirstpypkg myfirstpypkg.summary_stats.z_score(x) or from myfirstpypkg.summary_stats import z_score z_score(x) We can simplify this for the users by exporting the z_score() function so the user can simply do: from myfirstpypkg import z_score z_score(x) To allow for this you simply add the following to the src/myfirstpypkg/__init__.py file: from .summary_stats import z_score 6.4.6 Final checks &amp; version control Now before we commit our changes to git, let’s make sure everything still loads appropriately and passes all tests: pip install -e . pytest As long as everything is passing, we can now commit our changes, push to Github and then do a pull request to incorporate our changes from our current working branch to the develop branch. ```bash git add -A git commit -m ‘feat: add new validation &amp; summary stats &gt; Add validation function to ensure proper numeric sequence input. &gt; Add summary stat functions to compute standard deviation and z-score.’ git push –set-upstream origin ch6 Subdirectories are actually allowed but they can only be for OS-specific purposes and named unit/ or windows/. See this Stackoverflow question for details.↩ "],
["test.html", "7 Testing 7.1 Why test 7.2 What to test 7.3 Test organization 7.4 Types of tests 7.5 Writing tests 7.6 Additional resources 7.7 example 7.8 example", " 7 Testing Testing is a vital part of package development. It ensures that your code does what you want it to do. Although testing adds an additional step to your development workflow, it should not be overlooked. The goal of this chapter is to discuss the fundamentals of testing; however, this is a very cursory overview so we provide additional resources to learn more. 7.1 Why test Often when we start writing a package our instinct is to write a function, experiment with it in the console to see if it works, rinse and repeat until we have a solution we’re happy with. While this is “testing” your code, you’re only doing it informally. The problem with this approach is that when you come back to this code in 3 months time to add a new feature, you’ve probably forgotten some of the informal tests you ran the first time around. This makes it very easy to break code that used to work. Formalizing and automating the test structure and process helps with: Fewer bugs. Because you’re explicit about how your code should behave you will have fewer bugs. The reason why is a bit like the reason double entry book-keeping works: because you describe the behaviour of your code in two places, both in your code and in your tests, you are able to check one against the other. By following this approach to testing, you can be sure that bugs that you’ve fixed in the past will never come back to haunt you. Better code structure. Code that’s easy to test is usually better designed. This is because writing tests forces you to break up complicated parts of your code into separate functions that can work in isolation. This reduces duplication in your code. As a result, functions will be easier to test, understand and work with (it’ll be easier to combine them in new ways). Easier restarts. If you always finish a coding session by creating a failing test (e.g. for the next feature you want to implement), testing makes it easier for you to pick up where you left off: your tests will let you know what to do next. Robust code. If you know that all the major functionality of your package has an associated test, you can confidently make big changes without worrying about accidentally breaking something. For me, this is particularly useful when I think I have a simpler way to accomplish a task (usually the reason my solution is simpler is that I’ve forgotten an important use case!). 7.2 What to test There is a fine balance to writing tests. Each test that you write makes your code less likely to change inadvertently; but it also can make it harder to change your code on purpose. It’s hard to give good general advice about writing tests, but you might find these points helpful: Focus on testing the external interface to your functions - if you test the internal interface, then it’s harder to change the implementation in the future because as well as modifying the code, you’ll also need to update all the tests. Strive to test each behaviour in one and only one test. Then if that behavior later changes you only need to update a single test. You do not need to test all of your code; however, we often strive to test 85-95% of our code. Focus your time on code that you’re not sure about, is fragile, or has complicated interdependencies. That said, we often find we make the most mistakes when we falsely assume that the problem is simple and doesn’t need any tests. So there is definitely a case for striving for 100% coverage. Always write a test when you discover a bug or want to create a feature enhancement. Start by writing the tests, and then write the code that makes them pass. This reflects an important problem solving strategy: start by establishing your success criteria, how you know if you’ve solved the problem. You should not only write tests that outline the successful expected outcome of a function but you should also write tests to verify that expected messages, warnings, and errors are produced. 7.3 Test organization For both and packages the tests should live in a tests/ directory at the root of the package. The test files for both languages should start with test (i.e. test-validation.R, test_summary_stats.py). Within the tests/ directory there are some differences between the two languages and we will discuss that in the example sections. Tests are organized hierarchically: expectations and assertions are grouped into tests which are organized in files: An expectation or assertion is the atom of testing. It describes the expected result of a computation: Does it have the right value and right class? Does it produce error messages when it should? An expectation automates visual checking of results in the console. A test groups together one or more expectations/assertions to test the output from a simple function, a range of possibilities for a single parameter from a more complicated function, or tightly related functionality from across multiple functions. This is why they are sometimes called unit as they test one unit of functionality. A test file groups together multiple related tests. How you organize tests within files is your discretion; however, one best practice suggests that for every source code script there is a companion, similarly named test script (i.e. summary_stats.py &amp; test_summary_stats.py). 7.4 Types of tests There are many types of tests that you will read about when diving into the software test literature; however, the most common ones you should be thinking of initially are: unit tests: Tests that focus on the output from a single function, typically functions with lower levels of abstraction. Unit tests typically test the foundational building block functions of your package. This is why they are sometimes called unit as they test one unit of functionality. Unit tests should be fast so you can run them often and, preferablly not require any special environment to run them (i.e. a Spark session). Examples in our prototype package include the tests for my_mean() and my_sd(). integration tests: Tests that focus on processes and/or components that combine functionality from across multiple functions. As you build higher levels of abstraction, most of the underlying functionality of this abstraction is already tested with unit tests; however, the integration tests ensure that all the lower abstraction level functions work nicely with one another when combined. An example of an integration test in our prototype package is the test for the z_score() function. Often, integrated functionality becomes very large and sometimes can be slower to compute so it is not unusual for integration tests to be much slower than unit tests. However, we also do not need to run them as often as unit tests. 7.5 Writing tests Writing good tests takes time. It is not uncommon for people to write tests that are unfocused or too broad when first learning about software testing. Also, many people do not document their tests in a comprehensive way. This can lead to you coming back to a test in 3 months, when it does fail, scratching your head wondering what you were trying to do with the test. Given-When-Then is a style of representing tests that can help guide you in writing your tests, make your tests more focused and better documented. The essential idea is to break down writing a scenario (or test) into three sections: The given part describes the state of the world before you begin the behavior you’re specifying in this scenario. You can think of it as the pre-conditions to the test. The when section is the behavior that you’re specifying, or the specific functionality you are applying to the given state of the world. Finally the then section describes the changes you expect due to the specified behavior. A simple example is with our my_mean() function. In both languages we follow a common procedure: GIVEN a vector or list of integers from 0-10, WHEN we compute the mean value, THEN the result should be 5 Following this basic guide will make writing tests more explicit, easier, and better documented. 7.6 Additional resources Software testing is far too comprehensive to cover in one chapter. The above sections provide good foundations for your testing methodology and the and sections that follow will show a few more details about actual implementation. However, if you want to learn more about testing we recommend the following: Build your knowledge of general software testing philosophies: The Pragramatic Programmer (Ch. 41) Clean Code (Ch. 9) Test Driven Development Learn more about implementing software testing in and : Testing R Code testthat documentation Python Testing with pytest Multiply your Testing Effectiveness with Parameterized Testing pytest documentation 7.7 example The most common testing framework in is the testthat package. 7.7.1 Test organization The test/ directory in an should have the following: . └── tests └── testthat ├── test-script1.R ├── test-script2.R └── test-scriptn.R …where all test scripts start with test and fall in a tests/testhat/ directory. This is automatically set up for you in our template but you can easily create this from scratch with usethis::use_testthat(). When using this approach, each test script should be considered isolated from one another. If for some reason you need to create an object, environment or connection that gets used across multiple test files then you will see the following structure where objects, environments or connections are created in the setup.R file and then, if necessary, decommissioned/disconnected in the teardown.R file. . └── tests └── testthat ├── setup.R ├── test-script1.R ├── test-script2.R ├── test-scriptn.R └── teardown.R Test scripts are ran in order based on their name. So if you need, or desire, to run tests in a specific order than name them in an orderly fashion: test-01-name1.R test-02-name2.R test-03-name3.R 7.7.2 Writing a test We write tests in the following approach where: test_that() captures a suite of expectations, &quot;test context&quot; provides a clear, concise explanation of the purpose of the test, we can include any additional documentation in comments and expect_xxx() is the expectation we have for our test output. There are a variety of expect_xxx() functions that we can apply (i.e. expect_equal, ) test_that(&quot;test context&quot;, { # additional documentation expect_xxx() }) There are a variety of expect_xxx() functions that we can apply (i.e. expect_equal, expect_length, expect_failure, expect_message). Type testthat::expect_ + tab in your console to see all the options. Let’s take a look at our current test-validation.R file: test_that(&quot;inputs are a numeric vector&quot;, { expect_error(validate_numeric_vector(&quot;a&quot;)) expect_error(validate_numeric_vector(factor(1, 2, 3))) expect_error(validate_numeric_vector(list(1, 2, 3))) expect_silent(c(1, 2, 3)) expect_silent(c(TRUE, FALSE)) }) This test is currently a catch-all for our validate_numeric_vector() function. A better approach would be to break this up into specific functionality such as: test_that(&quot;non-vector inputs raise error&quot;, { # GIVEN a non-atomic vector input # WHEN validating said input # THEN an error is raised expect_error(validate_numeric_vector(matrix(1:3))) expect_error(validate_numeric_vector(list(1:3))) expect_error(validate_numeric_vector(data.frame(x = 1:3))) }) test_that(&quot;non-numeric vectors raise error&quot;, { # GIVEN a vector input # WHEN the vector is not numeric # THEN an error is raised expect_error(validate_numeric_vector(&quot;a&quot;)) expect_error(validate_numeric_vector(factor(1, 2, 3))) }) test_that(&quot;atomic vectors with numeric data are silent&quot;, { # GIVEN an atomic vector input # WHEN the vector contains numeric values or logical that can be coerced to numeric # THEN a silent return occurs expect_silent(c(1.0, 2.0, 3.0)) expect_silent(c(1L, 2L, 3L)) expect_silent(c(TRUE, FALSE)) }) The above is a little more explicit and methodical regarding what we expect to occur. If you run the above tests, you will actually see that a failure occurs. This is because a matrix technically is an atomic vector. We’ve found an edge case in our testing that we either need to decide to relax our unit test (if we are okay with a user supplying a matrix) or make our validate_numeric_vector function more robust to deal with matrix inputs. devtools::test() ## Loading myfirstpkg ## Testing myfirstpkg ## ✓ | OK F W S | Context ## ✓ | 3 | summary-stats ## x | 7 1 | validation ## ─────────────────────────────────────────────────────────────────────────────────────────────── ## test-validation.R:5: failure: non-vector inputs raise error ## `validate_numeric_vector(matrix(1:3))` did not throw an error. ## ─────────────────────────────────────────────────────────────────────────────────────────────── ## ## ══ Results ════════════════════════════════════════════════════════════════════════════════════ ## OK: 10 ## Failed: 1 ## Warnings: 0 ## Skipped: 0 This brings up the topic of what exactly we should be testing. 7.7.3 What to test This is a much harder concept to answer. We can certainly go over-board with testing if we try to capture every possible scenario. Our general approach is to test the main use-cases and then add to our test suite down the road as edge cases pop up. Defining the main use-cases is not always easy. We typically look for: a couple basic uses cases that we feel the vast majority of users will apply, a few expected edge cases such as if user supply NA or Inf values or if there are upper limits to the expected inputs (what if a user supplies an interest rate parameter with a negative value or value greater than 100%), expected messages, warnings, or errors designed specific for end-users. For example, our current test for our my_mean() function provides a very basic use case: test_that(&quot;mean of simple vector computes accurately&quot;, { x &lt;- 0:10 expect_equal(my_mean(x), 5) }) We would likely want to expand this initially to capture a few expected scenarios. The below provides three distinct test purposes for our my_mean() function. If you run the following you will see that the second test fails because our original implementation does not handle NA, Inf or Nan values. We would need to go back to that function and update it to deail with those values. test_that(&quot;mean of numeric vectors compute accurately&quot;, { # GIVEN a vector input # WHEN the data values are numeric or logical # THEN an arithmetic mean should be computed integer_inputs &lt;- 0:10 float_inputs &lt;- c(1.5, 2.5, 3.5) logical_inputs &lt;- c(TRUE, TRUE, FALSE, FALSE) negative_inputs &lt;- -10:10 expect_equal(my_mean(integer_inputs), 5) expect_equal(my_mean(float_inputs), 2.5) expect_equal(my_mean(negative_inputs), 0) }) test_that(&quot;Inf, NaN, and NA values are ignored&quot;, { # GIVEN a vector input that contains numeric values # WHEN the vector also contains Inf, NaN, and NA values # THEN these irregular values should be stripped and the arithmetic mean computed x &lt;- c(0:10, NA, Inf, NaN) expect_equal(my_mean(x), 5) }) test_that(&quot;Inadequate inputs raise error&quot;, { # GIVEN a user input # WHEN the input is not a vector with numeric values # THEN an error should be raised expect_error(my_mean(list(1:3))) expect_error(my_mean(data.frame(x = 1:3))) expect_error(my_mean(&quot;a&quot;)) expect_error(my_mean(factor(1, 2, 3))) }) 7.8 example The most common testing framework in is the pytest package. 7.8.1 Test organization The test/ directory in an should have the following: . └── tests ├── __init__.py ├── test_script1.py ├── test_script1.py └── test-scriptn.py …where all test scripts start with test. The init.py file is not necessary but it allows you to have duplicate file and test names without causing namespace clashes. This is especially helpful when you have multiple test directories. For example, we commonly group our tests in the following manner for larger packages where all unit tests go in one directory and all integration tests go in another. This allows you to easily test a single directory at a time with pytest tests/unit. . └── tests ├── unit │ ├── __init__.py │ ├── test_script1.py │ ├── test_script1.py │ └── test-scriptn.py └── integration ├── __init__.py ├── test_script1.py ├── test_script1.py └── test-scriptn.py If for some reason you need to create an object, environment or connection that gets used across multiple test files then you will see the following structure where objects, environments or connections are created in the conftest.py file, supplied to individual tests with a test fixture, and then decommissioned/disconnected thereafter. . └── tests ├── __init__.py ├── conftest.py ├── test_script1.py ├── test_script1.py └── test-scriptn.py ... Test scripts are ran in order based on their name. So if you need, or desire, to run tests in a specific order than name them in an orderly fashion: test_01_name1.py test_02_name2.py test_03_name3.py 7.8.2 Writing a test We write tests in the following approach where: def test_name_of_test() creates a test function that captures a suite of assertions, The test function docstring provides a clear, concise explanation of the purpose of the test, and assert is the assertion we have for our test output. def test_name_of_test(): &quot;&quot;&quot;Test docstring GIVEN ... WHEN ... THEN ... &quot;&quot;&quot; assert computed == expected Apart from assert, we can also test for exceptions, warning messages and the like with syntax such as with pytest.raises(TypeError):. We’ll demonstrate this shortly. Let’s take a look at our current test_validation.py file: def test_validate_sequence_type(): with pytest.raises(TypeError): _validate_numeric_sequence({}) def test_validate_sequence_numeric(): assert _validate_numeric_sequence(range(10)) == None with pytest.raises(TypeError): _validate_numeric_sequence(list(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;)) A better approach would be to break this up into specific functionality and create appropriate docstrings: def test_validate_sequence_type(): &quot;&quot;&quot;Non-sequence data type raises exception. GIVEN a non-sequence input WHEN validating said input THEN an error is raised &quot;&quot;&quot; with pytest.raises(TypeError): _validate_numeric_sequence({}) _validate_numeric_sequence(set()) def test_validate_non_numeric_sequence(): &quot;&quot;&quot;Non-numeric sequence raises error GIVEN a sequence input WHEN the sequence is not numeric THEN an error is raised &quot;&quot;&quot; with pytest.raises(TypeError): _validate_numeric_sequence(list(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;)) def test_validate_sequence_numeric(): &quot;&quot;&quot;Sequence with numeric data returns None GIVEN a sequence input WHEN the vector contains numeric values or logical that can be coerced to numeric THEN a silent return occurs &quot;&quot;&quot; assert _validate_numeric_sequence(range(10)) == None assert _validate_numeric_sequence([1, 2, 3]) == None assert _validate_numeric_sequence((True, False)) == None The above is a little more explicit and methodical regarding what we expect to occur. We can run these new tests on their own with the following. Note that -v is for verbose output which will print the path of the test. pytest -v tests/test_validation.py ======================================== test session starts ======================================== platform darwin -- Python 3.7.3, pytest-5.4.2, py-1.8.1, pluggy-0.13.1 -- /Users/b294776/Desktop/Workspace/Projects/misk/myfirstpypkg/venv/bin/python cachedir: .pytest_cache rootdir: /Users/b294776/Desktop/Workspace/Projects/misk/myfirstpypkg, inifile: setup.cfg collected 3 items tests/test_validation.py::test_validate_sequence_type PASSED [ 33%] tests/test_validation.py::test_validate_non_numeric_sequence PASSED [ 66%] tests/test_validation.py::test_validate_sequence_numeric PASSED [100%] ========================================= 3 passed in 0.02s ========================================= 7.8.3 What to test Exactly what we want to test is a much harder concept to answer. We can certainly go over-board with testing if we try to capture every possible scenario. Our general approach is to test the main use-cases and then add to our test suite down the road as edge cases pop up. Defining the main use-cases is not always easy. We typically look for: a couple basic uses cases that we feel the vast majority of users will apply, a few expected edge cases such as if user supplies a None value or if there are upper limits to the expected inputs (what if a user supplies an interest rate parameter with a negative value or value greater than 100%), expected messages, warnings, or errors designed specific for end-users. For example, our current test for our my_mean() function provides a very basic use case: def test_my_mean(): x = range(0, 11) assert my_mean(x) == 5 We would likely want to expand this initially to capture a few expected scenarios. The below provides three distinct test purposes for our my_mean() function. If you run the following you will see that the second test fails because our original implementation does not handle None values. We would need to go back to that function and update it to deail with those values. def test_my_mean_on_numeric_vectors(): &quot;&quot;&quot;Mean of numeric vectors compute accurately GIVEN a sequence input WHEN the data values are numeric or logical THEN an arithmetic mean should be computed &quot;&quot;&quot; assert my_mean(range(0, 11)) == 5 assert my_mean([1.5, 2.5, 3.5]) == 2.5 assert my_mean([True, True, False, False]) == 0.5 assert my_mean(range(-10, 11)) == 0 def test_my_mean_ignore_none(): &quot;&quot;&quot;None values are ignored GIVEN a sequence input that contains numeric values WHEN the sequence also contains `None` values THEN these irregular values should be stripped and the arithmetic mean computed &quot;&quot;&quot; x = list(range(0, 11)) x += [None] assert my_mean(x) == 5 def test_my_mean_inadequate_inputs(): &quot;&quot;&quot;Inadequate input raise error. GIVEN a user input WHEN the input is not a vector with numeric values THEN an error should be raised &quot;&quot;&quot; with pytest.raises(TypeError): my_mean(list(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;)) Also, note the first test and the repeated nature of the code. We could simplify this with what’s called “parametrizing” the test function. You can learn more about parametrization here. This is how you would implement it for the first test. Parametrizing is a great thing to learn! @pytest.mark.parametrize(&quot;input, expected&quot;, [(range(0, 11), 5), ([1.5, 2.5, 3.5], 2.5), ([True, True, False, False], 0.5), (range(-10, 11), 0), ] ) def test_my_mean_on_numeric_vectors(input, expected): &quot;&quot;&quot;Mean of numeric vectors compute accurately GIVEN a sequence input WHEN the data values are numeric or logical THEN an arithmetic mean should be computed &quot;&quot;&quot; assert my_mean(input) == expected "],
["object-docs.html", "8 Object Documentation 8.1 example 8.2 example", " 8 Object Documentation Documentation is one of the most important aspects of a good package. Without it, users won’t know how to use your package. Documentation is also useful for collaborating developers, and the future-you (so you remember what your functions were supposed to do), looking to extend your package. There are multiple forms of documentation. In this chapter, you’ll learn about object documentation, as accessed by ? or help(). Object documentation is a string literal specified in source code that is used, like a comment, to document a specific segment of code. The three main types of object documentation we’ll illustrate in this chapter are: Package-level documentation: Top level description for what your package does and can point users to additional resources if necessary. Module-level documentation: More common in than and helps to describe the purpose and contents of an individual module within a package. Function-level documentation: The function documentation that you have already been exposed to in earlier chapters. We are advocates for documenting as much as possible. It may slow you down initially but over the longterm it will speed up the development and maintenance process of a package. 8.1 example R object documentation is generated from the .Rd files in the man/ directory. If you look at one of the current .Rd files in your package’s man/ directory you’ll see LaTeX-like syntax. However, properly writing the .Rd files can be burdensome so we use roxygen2 to automate this process. Plus, it allows us to include documentation directly with our functionality. The sections that follow will illustrate the most common uses of roxygen2. 8.1.1 Package-level documentation You can use roxygen to provide a help page for your package as a whole. This is accessed with package?pkg_name (when the package is not loaded) or with ?pkg_name when it is loaded, and can be used to describe the most important components of your package. There’s no object that corresponds to a package, so you need to document NULL, and then manually label it with @docType package and @name &lt;package-name&gt;. This is also an excellent place to use the @section tag to divide up the page into useful categories. For example, you can include the following package documentation in a file called &lt;package-name&gt;.R: The @section tag allows you to create as many arbitrary sections as necessary. #&#39; myfirstpkg: A simple package to teach myself how to develop R packages.. #&#39; #&#39; The myfirstpkg: package provides X categories of important functions: #&#39; foo, bar and baz. #&#39; #&#39; @section Foo functions: #&#39; The foo functions ... #&#39; #&#39; @section Boo functions: #&#39; The bar functions ... #&#39; #&#39; @section Baz functions: #&#39; The baz functions ... #&#39; #&#39; @section Learn more: #&#39; \\itemize{ #&#39; \\item \\href{https://some.url.com}{Vignettes} Detailed example implementations. #&#39; \\item \\href{https://some.url.com}{Source code} Dig into the source code. #&#39; } #&#39; #&#39; @section Author(s): #&#39; \\strong{Maintainer}: Brad Boehmke \\email{bradleyboehmke@gmail.com} #&#39; #&#39; Authors: #&#39; \\itemize{ #&#39; \\item John Doe #&#39; \\item Jane Doe #&#39; } #&#39; #&#39; Other contributors: #&#39; \\itemize{ #&#39; \\item Sally Mae #&#39; \\item Paul Smith #&#39; } #&#39; #&#39; @docType package #&#39; @name myfirstpkg NULL #&gt; NULL Now if do the following: devtools::document(): to add a .Rd file for the package, devtools::load_all(): to load the package contents, ?myfirstpkg: to access the package help documentation You’ll see the following in the Help window: 8.1.2 Module-level documentation Documentating individual .R scripts (i.e. modules) is not common among R developers and, unlike Python, there is no formal approach to do this. However, as your package expands it is not uncommon for individual source code scripts to become long and contain many functions and/or classes. When this happens, it can be helpful to document the scripts to explain the purpose of the script (remember, you should be grouping like items within a script) and the functions/class it contains. To do this in you would just use comment blocks. For example, you could add the following to the top of the summary-stats.R script to provide a synopsis of the intent and contents of the scripts. Use Cmd/Ctrl + Shift + R to add the # Some lable ———- comment blocks. # Description --------------------------------------------------------------------- # Primary interface for summary statistics functionality # # A longer description can go here if greater details needs to be # provided that span multiple lines. # # Available classes: # - NA # # Available functions: # - z_score: Computes z-score of a numeric/logical vector. # - my_sd: Computes standard deviation of a numeric/logical vector. # - my_mean: Computes arithmentic mean of a numeric/logical vector. # Source code --------------------------------------------------------------------- ... 8.1.3 Function-level documentation Functions are the most commonly, and most important, documented object. As well as the introduction block, most functions have at least three tags: @param: Describes the function’s inputs or parameters. The description should provide a succinct summary of the type of the parameter (e.g., string, numeric vector) and, if not obvious from the name, what the parameter does. All parameters must be documented otherwise you will receive warnings when running devtools::check(). @examples: Provides executable R code showing how to use the function in practice. This is a very important part of the documentation because many people look at the examples first. For the purpose of illustration, it’s often useful to include code that causes an error. Or sometimes you may have examples that have other dependencies (i.e. creating a Spark environment). Wrapping your example(s) with \\dontrun{} allows you to include code in the example that is not run. @return: Describes the output from the function. This is not necessary but it is a good idea to always include it so it is clear to the consumer what to expect as output. This becomes even more important when your output type differs from your input type (i.e. input is a data frame but the output is a vector). We have already seen all three of these in action with our current my_mean() documentation: #&#39; Mean of a vector #&#39; #&#39; @description #&#39; Computes arithmetic mean of a vector with numeric or logical values. #&#39; #&#39; @param x A numeric or logical vector. #&#39; @param na.rm Boolean specifying whether or not to remove NA and NaN values.. #&#39; @param inf.rm Boolean specifying whether or not to remove Inf values. #&#39; #&#39; @return #&#39; The arithmetic mean of the values in x returned as a numeric vector of length one. #&#39; #&#39; @examples #&#39; x &lt;- 1:10 #&#39; my_mean(x) #&#39; #&#39; @export my_mean &lt;- function(x, na.rm = TRUE, inf.rm = TRUE) { validate_numeric_vector(x) x &lt;- validate_special_values(x, na.rm, inf.rm) total &lt;- sum(x) units &lt;- length(x) return(total / units) } 8.1.4 Additional syntax There are many additional syntax improvements you can make to your documentation. For example, you can make text italicized, bold or formatted as code, cross reference other documentation within the package, hyperlink to websites, include unordered and ordered lists, include math equations, and much more. See here for a quick reference guide of different documentation syntax formatting. 8.2 example Python object documentation is generated from docstrings. Docstrings should always use &quot;&quot;&quot;triple double quotes&quot;&quot;&quot; and are usually multiline. A great article on approaching Python project documentation - https://realpython.com/documenting-python-code/ 8.2.1 Package-level documentation The docstring for a package is contained in the __init__.py script and typically explains the main features of the package but can also list the modules and subpackages exported by the package. We could add similar package-level documentation as we did in the R example section by adding the following to myfirstpypkg/src/myfirstpypkg/__init__.py: __doc__ = &quot;&quot;&quot; myfirstpkg: A simple package to teach myself how to develop Python packages. ============================================================================ **myfirstpkg** is a Python package provides X categories of important functions: foo, bar and baz. It builds on top of basic built-in Python functionality without adding much new. However, it sure is helpful in advancing my understanding of Python packaging. Main Features ------------- Here are the key functionalities that myfirstpkg provides: - Foo functions: The foo functions ... - Boo functions: The boo functions ... - Baz functions: The baz functions ... Learn More ---------- - Detailed example implementations: https://some.url.com - Source code: https://some.url.com &quot;&quot;&quot; The above adds a __doc__ attribute to our package containing the docstring. So if you go to the terminal and import myfirstpypkg print(myfirstpypkg.__doc__) You will see the documentation print out: 8.2.2 Module-level documentation The docstring for individual .py scripts/modules can also be done with docstrings at the very top of the module. These generally explain the purpose of the module (remember, you should be grouping like items within a module) and list the classes, exceptions and functions (and any other objects) that are contained in the module, with a one-line summary of each. (These summaries generally give less detail than the summary line in the object’s docstring.) For example, you could add the following to the top of the summary_stats.py script to provide a synopsis of the intent and contents of the scripts. &quot;&quot;&quot;Primary interface for summary statistics functionality. A longer description can go here if greater details needs to be provided that span multiple lines. Available classes: - NA Available functions: - z_score: Computes z-score of a numeric/boolean sequence. - my_sd: Computes standard deviation of a numeric/boolean sequence. - my_mean: Computes arithmentic mean of a numeric/boolean sequence. &quot;&quot;&quot; Now, you or a developer can easily understand the contents contained in that module. And most editors will provide you the docstring information when hovering/highlighting references to the module. For example, in VS Code, when I place my cursor over the reference to the summary_stats in the __init__.py script I see the following: 8.2.3 Function-level documentation Functions are the most commonly, and most important, documented object. As well as the introduction block, most functions have at least three sections: Parameters: Describes the function’s inputs or parameters. The description should provide a succinct summary of the type of the parameter (e.g., bool, int, list, tuple) and, if not obvious from the name, what the parameter does. Returns: Describes the output from the function. This is not necessary but it is a good idea to always include it so it is clear to the consumer what to expect as output. This becomes even more important when your output type differs from your input type (i.e. input is a dictionary but the output is a list). Examples: Provides executable Python code showing how to use the function in practice. This is a very important part of the documentation because many people look at the examples first. It’s not uncommon to see other sections such as Attributes and Methods for class docstrings and Raises to describe when functions or methods will raise an exception. We have already seen all three of these in action with our current my_mean() documentation: def my_mean(x, rm_none = True): &quot;&quot;&quot; Mean of a sequence Computes arithmetic mean of a sequence with numeric or logical values. Parameters ---------- x A numeric or logical sequence. rm_none Boolean specifying whether or not to remove `None` values. Returns ------- The arithmetic mean of the values in x returned as a numeric value of length one. Examples -------- &gt;&gt;&gt; x = range(0, 11) ... my_mean(x) &quot;&quot;&quot; _validate_numeric_sequence(x) x = _validate_none_values(x, rm_none) total = sum(x) units = len(x) return total / units 8.2.4 Type hints There is another unique approach to documentating Python classes, functions, and methods called type hints. Type hints allow you to annotate required specifications of object types within the function call. For example, the following states that: the parameter name should be of type string the output of our function (as indicated with -&gt; str) should also be a string. def greeting(name: str) -&gt; str: return &#39;Hello &#39; + name Type hints are a more advanced topic but as you get more comfortable writing Python code, and especially when writing code others will use, type hints are definitely something you will want to learn and incorporate. You can learn more about type hints at: https://www.python.org/dev/peps/pep-0484/ https://docs.python.org/3/library/typing.html https://realpython.com/lessons/type-hinting/ "],
["changelog.html", "9 Changelog 9.1 What to log 9.2 What not to do 9.3 How to log 9.4 Exercises", " 9 Changelog A changelog is a file which contains a curated, chronologically ordered list of notable changes for each version of a project. A good changelog gives you a detailed view into the development process and makes it easier for users and contributors to see precisely what notable changes have been made between each release (or version) of the package. Whereas the README is designed for new users, the changelog is designed to for existing users. 9.1 What to log The changelog should contain an entry for every single version release of the package and contain the following information: Release version and date of release New features added Changes in existing functionality Deprecated functionality (features/functionality that soon-to-be removed) Removed functionality Bug fixes 9.2 What not to do 9.2.1 Commit log diffs Using commit log diffs as changelogs is a bad idea: they’re full of noise. Things like merge commits, commits with obscure titles, documentation changes, etc. The purpose of a commit is to document a step in the evolution of the source code. Some projects clean up commits, some don’t. The purpose of a changelog entry is to document the noteworthy difference, often across multiple commits, to communicate them clearly to end users. 9.2.2 Ignoring deprecations When people upgrade from one version to another, it should be painfully clear when something will break. If you do nothing else, list deprecations, removals, and any breaking changes in your changelog. For other developers, it should be very clear to upgrade to a version that lists deprecations, remove what’s deprecated, then upgrade to the version where the deprecations become removals. 9.3 How to log The changelog is typically contained in a file named CHANGELOG, NEWS, RELEASES, or HISTORY and is most commonly a .md or .rst file. We recommend you use CHANGELOG.md for packages and NEWS.md for since this is common convention. The template you used to create your first package alread includes a changelog (CHANGELOG.md for Python and NEWS.md for R. However, in R you can use usethis::use_news_md() to automatically create a NEWS.md file if ones does not already exist. The changelog should be written in a manner that makes it easy to see certain types of changes made. It should be in reverse chronological order meaning the latest version comes first and the release version and date should be displayed. It is common to keep an Unreleased section at the top to track upcoming changes until you have determined the appropriate version bump. How you capture the important changes in the version can vary but the below is a good approach where you use common headings to capture types of changes: Added Changed Deprecated Removed Fixed Refactor If an item is related to an issue in GitHub, include the issue number in parentheses, e.g. (#10). If an item is related to a pull request, include the pull request number and the author, e.g. (#101, @bradleyboehmke). Doing this makes it easy to navigate to the relevant issues on GitHub. Example: # Changelog All notable changes to this project will be documented in this file. ## Unreleased ### Added - Feature `xxx`: allows you to do some great stuff. &lt;Provide good summary and you can even supply examples&gt;. - Feature `xxx`: allows you do this other great stuff. ### Removed - Feature `xxx`: version 1.0.0 deprecated feature `xxx` has been removed. - Param `xxx`: version 1.0.0 deprecated param `xxx` has been removed. ### Fixed - Bug in `xxx`: was throwing `xxxx` error when doing &lt;provide good summary&gt; (#87). - Bug in `xxx`: was returning a integer instead of a float when &lt;summary&gt; (#86). ## Version 1.0.0 ### Added - Feature `xxx`: allows you to ... &lt;summary&gt;. - Param `xxx`: added to feature `xyz` to allow for... &lt;summary&gt;. ### Deprecated - Feature `xxx`: deprecated in favor of feature `xxx` (#98, @johndoe). - Param `xxx`: deprecated in favor of param `xxx` (#97, @janedoe). ## Version 0.9.1 ### Fixed - Bug in xxx: &lt;summary&gt; (#74). - Bug in xxx: &lt;summary&gt; (#73). - Bug in xxx: &lt;summary&gt; (#72). ## Version ... ... 9.4 Exercises Both the and package templates include a changelog file. Go to your and/or package and check out the existing changelog. Add appropriate sections within the current version you are working to capture the features added and any other changes you have made. "],
["readme.html", "10 README", " 10 README TBD… "],
["website.html", "11 Package Website", " 11 Package Website TBD… "],
["other.html", "12 Other Components", " 12 Other Components TBD… "],
["tbd.html", "13 TBD", " 13 TBD "]
]
